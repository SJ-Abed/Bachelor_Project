{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aC8YDqDC-f51",
        "outputId": "c6e1d90f-454f-472f-a6de-7ab6a747c608"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y2iAYCd5AZ1A",
        "outputId": "6378d4ae-6f3b-4918-e10e-acc630cc5f52"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/BC_Project\n"
          ]
        }
      ],
      "source": [
        "cd '/content/drive/My Drive/BC_Project/'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%html\n",
        "<!DOCTYPE html><html><body align=\"right\"><br><div style=\"direction:;ltr\"><p style=\"background-color: #F7FFCA; color:black; border:1px solid black; border-radius: 10px; font-size:32px; line-height:1.8; font-family: byekan; text-align:justify; padding-left: 50px; padding-right: 50px; padding: 15px;\" >\n",
        "Import libraries"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "id": "_oaf85Y-yYxO",
        "outputId": "85ad6dc6-6f35-49ef-d479-529b282792df"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<!DOCTYPE html><html><body align=\"right\"><br><div style=\"direction:;ltr\"><p style=\"background-color: #F7FFCA; color:black; border:1px solid black; border-radius: 10px; font-size:32px; line-height:1.8; font-family: byekan; text-align:justify; padding-left: 50px; padding-right: 50px; padding: 15px;\" >\n",
              "Import libraries\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "afDdlR_1Aabz"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from sklearn.decomposition import NMF\n",
        "from sklearn.preprocessing import normalize"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%html\n",
        "<!DOCTYPE html><html><body align=\"right\"><br><div style=\"direction:;ltr\"><p style=\"background-color: #F7FFCA; color:black; border:1px solid black; border-radius: 10px; font-size:32px; line-height:1.8; font-family: byekan; text-align:justify; padding-left: 50px; padding-right: 50px; padding: 15px;\" >\n",
        "Import Class table"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "id": "TmsisFm6zmU9",
        "outputId": "fe43bf25-ea36-4ffa-ed75-64c920b5136d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<!DOCTYPE html><html><body align=\"right\"><br><div style=\"direction:;ltr\"><p style=\"background-color: #F7FFCA; color:black; border:1px solid black; border-radius: 10px; font-size:32px; line-height:1.8; font-family: byekan; text-align:justify; padding-left: 50px; padding-right: 50px; padding: 15px;\" >\n",
              "Import Class table\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y-VDi4atB0eC"
      },
      "outputs": [],
      "source": [
        "#read class DataFrame and set its columns' names\n",
        "class_df = pd.read_csv('CLASS.csv')\n",
        "class_df=class_df.rename(columns={\"id\":\"classid\",\"name\":\"class_name\"})\n",
        "class_df=class_df.drop_duplicates()\n",
        "\n",
        "#assign classes with no parent to primary parents\n",
        "class_df.loc[[1],'primaryparentid'] = 1\n",
        "class_df.loc[[18],'primaryparentid'] = 42\n",
        "class_df.loc[[28],'primaryparentid'] = 1\n",
        "class_df.loc[[34],'primaryparentid'] = 125\n",
        "class_df.loc[[35],'primaryparentid'] = 94\n",
        "class_df.loc[[101],'primaryparentid'] = 93\n",
        "class_df.loc[[102],'primaryparentid'] = 16\n",
        "class_df.loc[[103,104,184],'primaryparentid'] = 103\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%html\n",
        "<!DOCTYPE html><html><body align=\"right\"><br><div style=\"direction:;ltr\"><p style=\"background-color: #F7FFCA; color:black; border:1px solid black; border-radius: 10px; font-size:32px; line-height:1.8; font-family: byekan; text-align:justify; padding-left: 50px; padding-right: 50px; padding: 15px;\" >\n",
        "Import Order table"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "id": "HAHxK3NRzvVm",
        "outputId": "355f8f95-b017-4097-8014-8b55e3c7995b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<!DOCTYPE html><html><body align=\"right\"><br><div style=\"direction:;ltr\"><p style=\"background-color: #F7FFCA; color:black; border:1px solid black; border-radius: 10px; font-size:32px; line-height:1.8; font-family: byekan; text-align:justify; padding-left: 50px; padding-right: 50px; padding: 15px;\" >\n",
              "Import Order table\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "O2qViAJ6Hkqy",
        "outputId": "6930418f-aa75-4525-d82a-414b5434c230"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" bid:    basket ID\\n    cid:    customer ID\\n    catid:  category ID\\n    iid:    item ID\\n    days:   days' count from that order\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "#read Orders DataFrame and set its columns' name.\n",
        "orders_df=pd.read_csv('ORDERS.csv')\n",
        "orders_df=orders_df.rename(columns={\"id\":\"bid\",\"id.1\":\"cid\",\"id.2\":\"catid\",'categoryid':'classid',\"id.3\":\"iid\",\"quantitystepcount\":\"quantity\",\"totaloriginalprice\":\"price\",\"?column?\":\"days\"})\n",
        "\"\"\" bid:    basket ID\n",
        "    cid:    customer ID\n",
        "    catid:  category ID\n",
        "    iid:    item ID\n",
        "    days:   days' count from that order\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mk9rL4LvQNcl"
      },
      "outputs": [],
      "source": [
        "#drop some missing values that contains a small part of the dataset\n",
        "# delete rows that contain wrong values\n",
        "orders_df.dropna(subset = ['classid','catid','iid','quantity','price','marketid'],inplace = True)\n",
        "orders_df = orders_df[orders_df['price']>300]\n",
        "orders_df = orders_df[orders_df['quantity']>0]\n",
        "\n",
        "#fill rows with null segmentation label with \"unlabeled\"\n",
        "orders_df.fillna('unlabeled',inplace = True)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%html\n",
        "<!DOCTYPE html><html><body align=\"right\"><br><div style=\"direction:;ltr\"><p style=\"background-color: #F7FFCA; color:black; border:1px solid black; border-radius: 10px; font-size:32px; line-height:1.8; font-family: byekan; text-align:justify; padding-left: 50px; padding-right: 50px; padding: 15px;\" >\n",
        "Convert DataFrame to a category base DataFrame"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "id": "v8lTll6sz72O",
        "outputId": "55b090a0-2921-4b39-9f2f-8d2e0f7f0135"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<!DOCTYPE html><html><body align=\"right\"><br><div style=\"direction:;ltr\"><p style=\"background-color: #F7FFCA; color:black; border:1px solid black; border-radius: 10px; font-size:32px; line-height:1.8; font-family: byekan; text-align:justify; padding-left: 50px; padding-right: 50px; padding: 15px;\" >\n",
              "Convert DataFrame to a category base DataFrame\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rKBKWiL3XDLI"
      },
      "outputs": [],
      "source": [
        "orders_df=orders_df.groupby(['bid', 'cid', 'checkoutdate','classid','catid', 'segmentationlabel', 'days', 'marketid']).sum().reset_index().sort_values('checkoutdate',ascending=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z2q9LHcJcrYR"
      },
      "outputs": [],
      "source": [
        "customer_order_count = orders_df.drop_duplicates(['cid', 'bid']).groupby('cid').size()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tl5eu9XL_D4i"
      },
      "outputs": [],
      "source": [
        "orders_df = orders_df[orders_df['cid'].isin(customer_order_count[customer_order_count > 2].index)]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_counts = orders_df.__deepcopy__().groupby('classid').count().reset_index()[['classid','bid']].rename(columns = {'bid':'rep'})\n",
        "(class_counts[ (class_counts['rep']<100)].merge(class_df)).merge(class_counts,left_on = 'primaryparentid',right_on = 'classid',how = \"left\")\n",
        "#delete rows that purchased less than 25 times in the whole dataset\n",
        "rare_items = class_counts[ (class_counts['rep']<25)]['classid']\n",
        "orders_df = orders_df[~orders_df.classid.isin(rare_items)]"
      ],
      "metadata": {
        "id": "LJJKP4aPwStZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bUDiLpCn_D2V"
      },
      "outputs": [],
      "source": [
        "#change format of checkout date from string to time\n",
        "def str_to_date(row):\n",
        "    return datetime.strptime(row, \"%Y-%m-%d %H:%M:%S.%f\")\n",
        "orders_df['checkoutdate'] = orders_df['checkoutdate'].apply(str_to_date)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ceX96blv_Dz5"
      },
      "outputs": [],
      "source": [
        "#add two columns that show first-time purchasing related to class or category\n",
        "\n",
        "# cat_first_checkout\n",
        "cat_first_checkout = orders_df.groupby(['cid', 'catid'], as_index=False)['checkoutdate'].min()\n",
        "cat_first_checkout.rename(columns={'checkoutdate': 'cat_first_checkout'}, inplace=True)\n",
        "orders_df = orders_df.merge(cat_first_checkout, on=['cid', 'catid'])\n",
        "\n",
        "# class_first_checkout\n",
        "class_first_checkout = orders_df.groupby(['cid', 'classid'], as_index=False)['checkoutdate'].min()\n",
        "class_first_checkout.rename(columns={'checkoutdate': 'class_first_checkout'}, inplace=True)\n",
        "orders_df = orders_df.merge(class_first_checkout, on=['cid', 'classid'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k0q-swul_DxT"
      },
      "outputs": [],
      "source": [
        "#with these functions we check whether this item/category is reordered or not.\n",
        "#if it isn't first order, then the related column takes 1, otherwise 0\n",
        "def check_reordered_cat(row):\n",
        "    if row.checkoutdate == row.cat_first_checkout:\n",
        "        return 0\n",
        "    return 1\n",
        "\n",
        "\n",
        "def check_reordered_class(row):\n",
        "    if row.checkoutdate == row.class_first_checkout:\n",
        "        return 0\n",
        "    return 1\n",
        "\n",
        "\n",
        "def get_week_day(row):\n",
        "    return row.weekday()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KGDPFcp7_Duu"
      },
      "outputs": [],
      "source": [
        "\n",
        "orders_df['day_of_week'] = orders_df['checkoutdate'].apply(get_week_day)\n",
        "orders_df['cat_reordered'] = orders_df.apply(check_reordered_cat, axis=1)\n",
        "orders_df['class_reordered'] = orders_df.apply(check_reordered_class, axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%html\n",
        "<!DOCTYPE html><html><body align=\"right\"><br><div style=\"direction:;ltr\"><p style=\"background-color: #F7FFCA; color:black; border:1px solid black; border-radius: 10px; font-size:32px; line-height:1.8; font-family: byekan; text-align:justify; padding-left: 50px; padding-right: 50px; padding: 15px;\" >\n",
        "Set labels and split prior data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "id": "kzAHnn1f00L-",
        "outputId": "ae815356-cea3-4deb-aaad-8d674fed5cb5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<!DOCTYPE html><html><body align=\"right\"><br><div style=\"direction:;ltr\"><p style=\"background-color: #F7FFCA; color:black; border:1px solid black; border-radius: 10px; font-size:32px; line-height:1.8; font-family: byekan; text-align:justify; padding-left: 50px; padding-right: 50px; padding: 15px;\" >\n",
              "Set labels and split prior data\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IqJ7TMNk_Dry"
      },
      "outputs": [],
      "source": [
        "# 1 for an item that is reordered in the last basket and 0 for otherwise\n",
        "\n",
        "def reordered_label(row):\n",
        "    if row.checkoutdate == row.last_basket_date:\n",
        "        return 1\n",
        "    return 0\n",
        "\n",
        "\n",
        "# split last basket for prediction and other for creating features\n",
        "def split_prior_data(orders_dff):\n",
        "    last_basket = orders_dff.groupby(['cid'], as_index=False)['days'].min()\n",
        "    last_basket.rename(columns={'days': 'prior_last_basket'}, inplace=True)\n",
        "    orders_dff = orders_dff.merge(last_basket, on=['cid'])\n",
        "\n",
        "    last_basket_date = orders_dff.groupby(['cid'], as_index=False)['checkoutdate'].max()\n",
        "    last_basket_date.rename(columns={'checkoutdate': 'last_basket_date'}, inplace=True)\n",
        "    orders_dff = orders_dff.merge(last_basket_date, on=['cid'])\n",
        "\n",
        "    orders_dff['days'] -= orders_dff['prior_last_basket']\n",
        "    orders_dff['prior_last_basket'] = 0\n",
        "\n",
        "    orders_dff.sort_values(by=['cid', 'checkoutdate'], inplace=True)\n",
        "    last_so_id = orders_dff.drop_duplicates(subset=['cid'], keep='last')\n",
        "    prior_data = orders_dff[~orders_dff['bid'].isin(last_so_id['bid'])]\n",
        "\n",
        "    train_validation_data = orders_dff\n",
        "    train_validation_data.sort_values(by=['cid', 'checkoutdate'], inplace=True)\n",
        "    train_validation_data = train_validation_data[(((train_validation_data['cat_reordered'] == 1) &\n",
        "                                                    (train_validation_data['checkoutdate'] ==\n",
        "                                                     train_validation_data['last_basket_date']))\n",
        "                                                   | (train_validation_data['checkoutdate'] !=\n",
        "                                                      train_validation_data['last_basket_date']))]\n",
        "    train_validation_data.drop_duplicates(inplace=True, subset=['cid', 'catid'], keep='last')\n",
        "    del train_validation_data['bid']\n",
        "    train_validation_data = train_validation_data.merge(last_so_id[['cid', 'bid']], on='cid')\n",
        "    train_validation_data['reorder_label'] = train_validation_data.apply(reordered_label, axis=1)\n",
        "\n",
        "    del prior_data['last_basket_date']\n",
        "    del prior_data['prior_last_basket']\n",
        "    return prior_data, train_validation_data[['cid', 'bid','catid', 'classid', 'reorder_label']]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "prior_data_n_1, test_validation_data = split_prior_data(orders_df.__deepcopy__())\n",
        "prior_data_n_2, train_validation_data = split_prior_data(prior_data_n_1.__deepcopy__())\n",
        "prior_data_n_3, train_validation_data_2 = split_prior_data(prior_data_n_2.__deepcopy__())\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%html\n",
        "<!DOCTYPE html><html><body align=\"right\"><br><div style=\"direction:;ltr\"><p style=\"background-color: #F7FFCA; color:black; border:1px solid black; border-radius: 10px; font-size:32px; line-height:1.8; font-family: byekan; text-align:justify; padding-left: 50px; padding-right: 50px; padding: 15px;\" >\n",
        "Generate Features"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "id": "UcWKUR5_062Y",
        "outputId": "71502354-7000-4046-d203-b6e608dc1574"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<!DOCTYPE html><html><body align=\"right\"><br><div style=\"direction:;ltr\"><p style=\"background-color: #F7FFCA; color:black; border:1px solid black; border-radius: 10px; font-size:32px; line-height:1.8; font-family: byekan; text-align:justify; padding-left: 50px; padding-right: 50px; padding: 15px;\" >\n",
              "Generate Features\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZjiVKQzn_Doi"
      },
      "outputs": [],
      "source": [
        "\n",
        "# user feature\n",
        "def generate_user_features(prior_data):\n",
        "    user_features = pd.DataFrame(columns=['user_id'])\n",
        "    user_features['user_id'] = prior_data['cid'].sort_values().unique()\n",
        "    user_reorder_rate = prior_data.groupby([\"cid\", \"cat_reordered\"])['cat_reordered'].count().groupby(level=0).apply(\n",
        "        lambda x: x / float(x.sum())).reset_index(name='cat_reorder_rate')\n",
        "    user_reorder_rate = user_reorder_rate.pivot(index='cid', columns='cat_reordered', values=['cat_reorder_rate'])\n",
        "    user_reorder_rate = pd.DataFrame(user_reorder_rate.to_records())\n",
        "    user_reorder_rate.columns = ['user_id', '0', '1']\n",
        "    user_reorder_rate.set_index(\"user_id\", inplace=True)\n",
        "    user_reorder_rate.fillna(0, inplace=True)\n",
        "    user_reorder_rate.reset_index(inplace=True)\n",
        "    user_features['user_cat_reorder_rate'] = user_reorder_rate['1']\n",
        "\n",
        "    # Get count of all unique cat for every user\n",
        "    user_features['user_unique_cats'] = \\\n",
        "        prior_data.groupby([\"cid\"])['catid'].nunique().reset_index(name='unique')['unique']\n",
        "\n",
        "    # Get count of all cat ordered by user\n",
        "    user_features['user_total_cats'] = prior_data.groupby([\"cid\"])['catid'].size().reset_index(name='count')['count']\n",
        "\n",
        "    # Get mean cat per user = Average cart size of user\n",
        "    df = prior_data.groupby([\"cid\", \"bid\"])['catid'].count().reset_index(name='cart_size') \\\n",
        "        .groupby('cid')['cart_size'].mean().reset_index()\n",
        "    user_features['user_avg_cart_size'] = df['cart_size']\n",
        "\n",
        "    # Get average days between 2 orders for every user\n",
        "    df = \\\n",
        "        prior_data.groupby([\"cid\", \"bid\"])['days'].max().reset_index(name='days_of_orders') \\\n",
        "            .groupby('cid')['days_of_orders'].diff()\n",
        "    df = pd.DataFrame({'days_between_orders': -df})\n",
        "    df['user_id'] = list(prior_data.groupby([\"cid\", \"bid\"])['days'].max().reset_index(level=0)['cid'])\n",
        "    df.dropna(inplace=True)\n",
        "    df = df.groupby('user_id', as_index=False)['days_between_orders'].mean()\n",
        "\n",
        "    user_features = user_features.merge(df, on='user_id')\n",
        "\n",
        "    # get user product reorder ratio\n",
        "    # number of unique products reordered / number of unique products ordered\n",
        "\n",
        "    # get user cats reorder ratio\n",
        "    # number of unique cats reordered / number of unique cats ordered\n",
        "\n",
        "    df = prior_data.groupby([\"cid\"])['catid'].nunique().reset_index(name='user_unique_cats')\n",
        "    df = df.merge(prior_data[prior_data['cat_reordered'] == 1].groupby([\"cid\"])['catid'].nunique().reset_index(\n",
        "        name='user_reordered_cats'), on='cid')\n",
        "    df.fillna(0, inplace=True)\n",
        "    df['user_reordered_cats_ratio'] = df['user_reordered_cats'] / df['user_unique_cats']\n",
        "    del user_features['user_unique_cats']\n",
        "    user_features = user_features.merge(df, left_on='user_id', right_on='cid')\n",
        "    del user_features['cid']\n",
        "\n",
        "    # get user classes reorder ratio\n",
        "    # number of unique classes reordered / number of unique classes ordered\n",
        "    df = prior_data.groupby([\"cid\"])['classid'].nunique().reset_index(name='user_unique_classes')\n",
        "    df = df.merge(prior_data[prior_data['cat_reordered'] == 1].groupby([\"cid\"])['classid'].nunique().reset_index(\n",
        "        name='user_reordered_classes'), on='cid')\n",
        "    df.fillna(0, inplace=True)\n",
        "    df['user_reordered_classes_ratio'] = df['user_reordered_classes'] / df['user_unique_classes']\n",
        "    user_features = user_features.merge(df, left_on='user_id', right_on='cid')\n",
        "    del user_features['cid']\n",
        "\n",
        "    return user_features\n",
        "\n",
        "\n",
        "user_features_n_1 = generate_user_features(prior_data_n_1)\n",
        "user_features_n_2 = generate_user_features(prior_data_n_2)\n",
        "user_features_n_3 = generate_user_features(prior_data_n_3)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yOY7a81P_QkD"
      },
      "outputs": [],
      "source": [
        "\n",
        "#  Cat Features :\n",
        "def generate_cat_features(prior_data):\n",
        "    # create an empty dataframe\n",
        "    product_features = pd.DataFrame(columns=['catid'])\n",
        "\n",
        "    # add cat_name\n",
        "    product_features['catid'] = prior_data['catid'].sort_values().unique()\n",
        "\n",
        "    ############# average days between cat reorder\n",
        "    df = prior_data.sort_values(by=['cid','catid','checkoutdate'])[['cid','bid','catid','checkoutdate','days','price']]\n",
        "    df['days_since_prior_cat_order']= -df.groupby(['cid', 'catid'])['days'].transform(lambda x: x.diff())\n",
        "    days_to_next = list(df['days_since_prior_cat_order'].iloc[1:])\n",
        "    days_to_next.append(np.nan)\n",
        "    # df = \\\n",
        "    #     prior_data.groupby([\"cid\", \"bid\"])['days'].max().reset_index(name='days_of_orders') \\\n",
        "    #         .groupby('cid')['days_of_orders'].diff()\n",
        "    # df = pd.DataFrame({'days_between_orders': -df})\n",
        "    df['days_to_next_order'] = days_to_next\n",
        "    df['price'] = df['price'].astype(float)\n",
        "    df['price_day_ratio']=df['price']/df['days_to_next_order']\n",
        "    df.loc[abs(df['days_to_next_order'])==0, \"price_day_ratio\"] = np.nan\n",
        "    df2=df.groupby([\"catid\"])['price_day_ratio'].mean().reset_index(name='ave_price_day_ratio')\n",
        "    df2.fillna(0, inplace=True)\n",
        "    product_features=product_features.merge(df2,on=['catid'])\n",
        "    ###############################3\n",
        "\n",
        "    # get reorder_rate for each cat\n",
        "    # reorder_rate = reorders / total orders\n",
        "    df = pd.DataFrame({'cat_reorder_rate': prior_data.groupby(['catid', 'cat_reordered'])['cat_reordered'].\\\n",
        "                      count().groupby(level=0).apply(lambda x: x / float(x.sum()))}).reset_index()\n",
        "\n",
        "    # get data of reordered cat only\n",
        "    new_df = df[df['cat_reordered'] == 1]\n",
        "    new_df['cat_reorder_rate'] = new_df['cat_reorder_rate'] * new_df['cat_reordered']\n",
        "\n",
        "    # handling for cat which were never reordered, hence reorder_rate = 0.0\n",
        "    new_df_1 = df[(df['cat_reordered'] == 0) & (df['cat_reorder_rate'] == float(1.0))]\n",
        "    new_df_1['cat_reorder_rate'] = new_df_1['cat_reorder_rate'] * new_df_1['cat_reordered']\n",
        "    new_df = new_df.append(new_df_1)\n",
        "\n",
        "    # drop other columns of the new_df and sort values by cat name to align with cat features dataframe\n",
        "    new_df.drop('cat_reordered', axis=1, inplace=True)\n",
        "    new_df.sort_values(by='catid', inplace=True)\n",
        "    new_df = new_df.reset_index(drop=True)\n",
        "\n",
        "    # add to feat_1 of cat_features dataframe\n",
        "    product_features['cat_reorder_rate'] = new_df['cat_reorder_rate']\n",
        "\n",
        "    #  generate boolean values if cat belongs to below classes\n",
        "    # cat = pd.DataFrame()\n",
        "    # all_cat = cid_iid_df[['iid','iname','classid','catid']]\n",
        "    products = orders_df[['catid', 'classid']].drop_duplicates().reset_index()\n",
        "\n",
        "    # from collections import Counter\n",
        "    # x = all_cats.classid.values.tolist()\n",
        "    # common = pd.DataFrame(Counter(x).most_common())\n",
        "\n",
        "    products['isMilk'] = products['classid'].apply(lambda x: x == 51).astype(int)\n",
        "    products['isSeifijat'] = products['classid'].apply(lambda x: x == 57).astype(int)\n",
        "    products['isFruits'] = products['classid'].apply(lambda x: x == 21).astype(int)\n",
        "    products['isLabaniat'] = products['classid'].apply(lambda x: x == 2 or x == 55).astype(int)\n",
        "    products['isProtein'] = products['classid'].apply(lambda x: x == 156 or x == 68).astype(int)\n",
        "    products['isSnack'] = products['classid'].apply(lambda x: x == 131 or x == 132 or x == 133).astype(int)\n",
        "    products['isKalayeAsasi'] = products['classid'].apply(\n",
        "        lambda x: x == 9 or x == 45 or x == 92 or x == 69 or x == 71).astype(int)\n",
        "\n",
        "    new_product_feat = products[\n",
        "        ['isMilk', 'isSeifijat', 'isFruits', 'isLabaniat', 'isProtein', 'isSnack', 'isKalayeAsasi']]\n",
        "\n",
        "    # reduce sparsity using NMF\n",
        "    # ref:https://www.kaggle.com/themissingsock/matrix-decomposition-with-buyer-data\n",
        "\n",
        "    nmf = NMF(n_components=3)\n",
        "    model = nmf.fit(new_product_feat)\n",
        "    W = model.transform(new_product_feat)\n",
        "    prod_data = pd.DataFrame(normalize(W))\n",
        "\n",
        "    prod_data.columns = ['p_reduced_feat_1', 'p_reduced_feat_2', 'p_reduced_feat_3']\n",
        "    products.drop(['isMilk', 'isSeifijat', 'isFruits', 'isLabaniat', 'isProtein', 'isSnack', 'isKalayeAsasi'],\n",
        "                  axis=1, inplace=True)\n",
        "\n",
        "    product_features['p_reduced_feat_1'] = prod_data['p_reduced_feat_1']\n",
        "    product_features['p_reduced_feat_2'] = prod_data['p_reduced_feat_2']\n",
        "    product_features['p_reduced_feat_3'] = prod_data['p_reduced_feat_3']\n",
        "\n",
        "    # merge dept_reorder_rate and aisle_reorder_rate to existing product features\n",
        "\n",
        "    del df, new_df, new_df_1, new_product_feat, model, prod_data\n",
        "    return product_features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6idT7aSd_Dl0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lmmwHsMX_Di_"
      },
      "outputs": [],
      "source": [
        "\n",
        "def generate_user_cat_features(prior_data):\n",
        "    # create an empty dataframe\n",
        "    user_cat_features = pd.DataFrame(columns=['cid', 'catid'])\n",
        "\n",
        "    # get unique user-cat pairs ( total data is reduced by 60 %)\n",
        "    # prior_train_orders.groupby([\"user_id\",\"cat_id\"]).size().shape[0]/prior_train_orders.shape[0]  - 0.409\n",
        "    # add user and cat to dataframe\n",
        "    u_t = prior_data.groupby([\"cid\", \"catid\"]).size().reset_index()\n",
        "    user_cat_features[\"cid\"] = u_t[\"cid\"]\n",
        "    user_cat_features[\"catid\"] = u_t[\"catid\"]\n",
        "\n",
        "    # How frequently user ordered the cat ?\n",
        "    # #times user ordered the cat/ #times user placed an order\n",
        "    df = prior_data.groupby([\"cid\", \"catid\"])[\"cat_reordered\"].size()\n",
        "    df = df / prior_data.groupby([\"cid\"]).size()\n",
        "    df = df.reset_index(name='order_rate')\n",
        "    df.fillna(0., inplace=True)\n",
        "    user_cat_features[\"u_t_order_rate\"] = df[\"order_rate\"]\n",
        "\n",
        "    # How frequently user reordered the cat ?\n",
        "    # #times user reordered the cat/ #times user ordered the cat\n",
        "    df = prior_data[prior_data[\"cat_reordered\"] == 1].groupby([\"cid\", \"catid\"])[\"cat_reordered\"].size()\n",
        "    df = df / prior_data.groupby([\"cid\", \"catid\"]).size()\n",
        "    df = df.reset_index(name='reorder_rate')\n",
        "    df.fillna(0., inplace=True)\n",
        "    user_cat_features[\"u_t_reorder_rate\"] = df[\"reorder_rate\"]\n",
        "\n",
        "    # Number of orders placed since the cat was last ordered ?\n",
        "\n",
        "    ############# average days between cat reorder\n",
        "    df = prior_data.sort_values(by=['cid','catid','checkoutdate'])[['cid','bid','catid','checkoutdate','days','price']]\n",
        "    df['days_since_prior_cat_order']= -df.groupby(['cid', 'catid'])['days'].transform(lambda x: x.diff())\n",
        "    days_to_next = list(df['days_since_prior_cat_order'].iloc[1:])\n",
        "    days_to_next.append(np.nan)\n",
        "    # df = \\\n",
        "    #     prior_data.groupby([\"cid\", \"bid\"])['days'].max().reset_index(name='days_of_orders') \\\n",
        "    #         .groupby('cid')['days_of_orders'].diff()\n",
        "    # df = pd.DataFrame({'days_between_orders': -df})\n",
        "    df['days_to_next_order'] = days_to_next\n",
        "    df['price'] = df['price'].astype(float)\n",
        "    df['price_day_ratio']=df['price']/df['days_to_next_order']\n",
        "    df.loc[abs(df['days_to_next_order'])==0, \"price_day_ratio\"] = np.nan\n",
        "    df2=df.groupby([\"cid\", \"catid\"])['price_day_ratio'].mean().reset_index(name='user_ave_price_day_ratio')\n",
        "    df2.fillna(0, inplace=True)\n",
        "    user_cat_features=user_cat_features.merge(df2,on=['cid','catid'])\n",
        "\n",
        "\n",
        "    df = prior_data.sort_values(by=['cid','catid','checkoutdate'])[['cid','bid','catid','checkoutdate','days','price']].drop_duplicates(subset=['cid','catid'],keep='last')\n",
        "    df['price'] = df['price'].astype(float)\n",
        "    df['user_days_price_ratio_since_prior']=df['price']/(df['days']+0.4)\n",
        "    user_cat_features=user_cat_features.merge(df[['cid','catid','user_days_price_ratio_since_prior']],on=['cid','catid'])\n",
        "\n",
        "    ###############################3\n",
        "\n",
        "\n",
        "    #  Get Number of orders\n",
        "    prior_data_order_number = prior_data.groupby('cid').apply(\n",
        "        lambda x: x.drop_duplicates(subset='bid').reset_index(drop=True).\n",
        "            reset_index()[['cid', 'bid', 'index']].merge(x, on=['cid', 'bid'])).reset_index(drop=True)\n",
        "\n",
        "    prior_data_order_number = prior_data_order_number.rename({'index': 'order_number'}, axis='columns')\n",
        "\n",
        "\n",
        "\n",
        "    # Get last order_number placed by user , subtract with last order_number with the CAT in cart\n",
        "    df = prior_data_order_number.groupby([\"cid\", \"catid\"])['order_number'].max().reset_index()\n",
        "    df_2 = prior_data_order_number.groupby([\"cid\"])['order_number'].max().reset_index()\n",
        "    new_df = pd.merge(df, df_2, how='outer', left_on=['cid'], right_on=['cid'])\n",
        "    new_df['order_number_diff'] = new_df['order_number_y'] - new_df['order_number_x']\n",
        "    user_cat_features['u_t_orders_since_last'] = new_df['order_number_diff']\n",
        "\n",
        "    # Get last order_number placed by user , subtract with last order_number with the CLASS in cart\n",
        "    df = prior_data_order_number.groupby([\"cid\", \"classid\"])['order_number'].max().reset_index()\n",
        "    df_2 = prior_data_order_number.groupby([\"cid\"])['order_number'].max().reset_index()\n",
        "    new_df = pd.merge(df, df_2, how='outer', left_on=['cid'], right_on=['cid'])\n",
        "    new_df['order_number_diff'] = new_df['order_number_y'] - new_df['order_number_x']\n",
        "    user_cat_features['u_c_orders_since_last'] = new_df['order_number_diff']\n",
        "\n",
        "    # max_streak\n",
        "    def max_streak(row):\n",
        "        #  Function to calculate the maximum number of orders in a row which contains reorders of a cat\n",
        "        maxx = 0\n",
        "        summ = 0\n",
        "        for i in range(len(row) - 1):\n",
        "            if row[i + 1] - row[i] == 1:\n",
        "                summ += 1\n",
        "            else:\n",
        "                if summ > maxx:\n",
        "                    maxx = summ\n",
        "                summ = 0\n",
        "        return maxx\n",
        "\n",
        "    df = prior_data_order_number.groupby([\"cid\", \"catid\"])['order_number'].apply(list).reset_index(name='max_streak_cat')\n",
        "\n",
        "    df['max_streak_cat'] = [max_streak(df['max_streak_cat'].iloc[i]) for i in range(len(df))]\n",
        "    user_product_features = pd.merge(user_cat_features, df, on=[\"cid\", \"catid\"])\n",
        "\n",
        "    del df, prior_data_order_number , df2 ,df_2\n",
        "    return user_product_features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d5VxI79m_Ddc"
      },
      "outputs": [],
      "source": [
        "cat_features_n_1 = generate_cat_features(prior_data_n_1)\n",
        "cat_features_n_2 = generate_cat_features(prior_data_n_2)\n",
        "cat_features_n_3 = generate_cat_features(prior_data_n_3)\n",
        "\n",
        "user_cat_features_n_1 = generate_user_cat_features(prior_data_n_1)\n",
        "user_cat_features_n_2 = generate_user_cat_features(prior_data_n_2)\n",
        "user_cat_features_n_3 = generate_user_cat_features(prior_data_n_3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "afqnhNFO_Dam"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "feature : how frequently product was reordered on any given hour ?\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def cat_day(prior_data):\n",
        "    df = prior_data.groupby(['catid', 'day_of_week'])[\"cat_reordered\"].size()\n",
        "    df = df / prior_data.groupby([\"catid\"]).size()\n",
        "    df = df.reset_index(name='cat_week_reorder_rate')\n",
        "    return df\n",
        "\n",
        "\n",
        "def class_day(prior_data):\n",
        "    df = prior_data.groupby(['classid', 'day_of_week'])[\"class_reordered\"].size()\n",
        "    df = df / prior_data.groupby([\"classid\"]).size()\n",
        "    df = df.reset_index(name='class_week_reorder_rate')\n",
        "    return df\n",
        "\n",
        "\n",
        "def get_days_since_prior(orders_df):\n",
        "    customer_order_days = orders_df.sort_values(by='checkoutdate').groupby([\"cid\", \"bid\"], as_index=False)['days'].max()\n",
        "    df = customer_order_days.groupby(['cid']).diff()['days']\n",
        "    df = pd.DataFrame({'days_since_prior_order': -df})\n",
        "    df[['cid', 'bid']] = customer_order_days[['cid', 'bid']]\n",
        "    df.dropna(inplace=True)\n",
        "    df['days_since_prior_order'] = df['days_since_prior_order'].astype(int)\n",
        "    days_since_prior = df.merge(orders_df, on=['cid', 'bid'])\n",
        "    return days_since_prior\n",
        "\n",
        "# last_cid_so_prior = days_since_prior.drop_duplicates(subset=['cid'], keep='last')\n",
        "\n",
        "\n",
        "\n",
        "test_days_since_prior = get_days_since_prior(orders_df.__deepcopy__())\n",
        "train_days_since_prior = get_days_since_prior(prior_data_n_1.__deepcopy__())\n",
        "\n",
        "train_validation_data = train_validation_data.merge(train_days_since_prior[['cid', 'bid', 'days_since_prior_order',\n",
        "                                                                            'day_of_week', 'checkoutdate']],\n",
        "                                                    on=['cid', 'bid'])\n",
        "train_validation_data.drop_duplicates(inplace=True)\n",
        "train_days_since_prior = train_days_since_prior[~train_days_since_prior['bid'].isin(train_validation_data['bid'])]\n",
        "\n",
        "test_validation_data = test_validation_data.merge(\n",
        "    test_days_since_prior[['cid', 'bid', 'days_since_prior_order', 'day_of_week', 'checkoutdate']],\n",
        "    on=['cid', 'bid'])\n",
        "test_validation_data.drop_duplicates(inplace=True)\n",
        "test_days_since_prior = test_days_since_prior[~test_days_since_prior['bid'].isin(test_validation_data['bid'])]\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kleoUoFs_DX4"
      },
      "outputs": [],
      "source": [
        "\n",
        "def cat_days_since_prior(days_since_prior):\n",
        "    df = days_since_prior.groupby(['catid', 'days_since_prior_order'])[\"cat_reordered\"].size()\n",
        "    df = df / days_since_prior.groupby([\"catid\"]).size()\n",
        "    df = df.reset_index(name='t_days_since_prior_order_reorder_rate')\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "def class_days_since_prior(days_since_prior):\n",
        "    df = days_since_prior.groupby(['classid', 'days_since_prior_order'])[\"class_reordered\"].size()\n",
        "    df = df / days_since_prior.groupby([\"classid\"]).size()\n",
        "    df = df.reset_index(name='c_days_since_prior_order_reorder_rate')\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "def user_days_since_prior(days_since_prior):\n",
        "    \"\"\"\n",
        "    feature: how frequently user reordered any product given difference between 2 orders in days ?\n",
        "    \"\"\"\n",
        "    df = days_since_prior.groupby(['cid', 'days_since_prior_order'])[\"cat_reordered\"].size()\n",
        "    df = df / days_since_prior.groupby([\"cid\"]).size()\n",
        "    df = df.reset_index(name='u_days_since_prior_order_reorder_rate')\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def u_t_days_since_prior(days_since_prior):\n",
        "    df = days_since_prior.groupby([\"cid\", \"catid\", \"days_since_prior_order\"])[\"cat_reordered\"].size()\n",
        "    df = df / days_since_prior.groupby([\"cid\", \"catid\"]).size()\n",
        "    df = df.reset_index(name='u_t_days_since_prior_reorder_rate')\n",
        "    return df\n",
        "\n",
        "\n",
        "def u_c_days_since_prior(days_since_prior):\n",
        "    df = days_since_prior.groupby([\"cid\", \"classid\", \"days_since_prior_order\"])[\"class_reordered\"].size()\n",
        "    df = df / days_since_prior.groupby([\"cid\", \"classid\"]).size()\n",
        "    df = df.reset_index(name='u_c_days_since_prior_reorder_rate')\n",
        "    return df\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "brAPb1-0_DU2"
      },
      "outputs": [],
      "source": [
        "\n",
        "# merge features\n",
        "train_validation_merge = train_validation_data.merge(user_features_n_2, left_on='cid', right_on='user_id')\n",
        "# train_validation_merge = train_validation_merge.merge(product_day(train_days_since_prior), how='left',\n",
        "#                                                       on=['iid', 'day_of_week'])\n",
        "train_validation_merge = train_validation_merge.merge(cat_day(train_days_since_prior), how='left',\n",
        "                                                      on=['catid', 'day_of_week'])\n",
        "train_validation_merge = train_validation_merge.merge(class_day(train_days_since_prior), how='left',\n",
        "                                                      on=['classid', 'day_of_week'])\n",
        "\n",
        "test_validation_merge = test_validation_data.merge(user_features_n_1, left_on='cid', right_on='user_id')\n",
        "# test_validation_merge = test_validation_merge.merge(product_day(test_days_since_prior), how='left',\n",
        "#                                                     on=['iid', 'day_of_week'])\n",
        "test_validation_merge = test_validation_merge.merge(cat_day(test_days_since_prior), how='left',\n",
        "                                                    on=['catid', 'day_of_week'])\n",
        "test_validation_merge = test_validation_merge.merge(class_day(test_days_since_prior), how='left',\n",
        "                                                    on=['classid', 'day_of_week'])\n",
        "\n",
        "# product/cat/class\n",
        "# train_validation_merge = train_validation_merge.merge(product_days_since_prior(train_days_since_prior), how='left',\n",
        "#                                                       left_on=['iid', 'days_since_prior_order'],\n",
        "#                                                       right_on=['iid', 'days_since_prior_order'])\n",
        "train_validation_merge = train_validation_merge.merge(cat_days_since_prior(train_days_since_prior), how='left',\n",
        "                                                      left_on=['catid', 'days_since_prior_order'],\n",
        "                                                      right_on=['catid', 'days_since_prior_order'])\n",
        "train_validation_merge = train_validation_merge.merge(class_days_since_prior(train_days_since_prior), how='left',\n",
        "                                                      left_on=['classid', 'days_since_prior_order'],\n",
        "                                                      right_on=['classid', 'days_since_prior_order'])\n",
        "\n",
        "# test_validation_merge = test_validation_merge.merge(product_days_since_prior(test_days_since_prior), how='left',\n",
        "#                                                     left_on=['iid', 'days_since_prior_order'],\n",
        "#                                                     right_on=['iid', 'days_since_prior_order'])\n",
        "test_validation_merge = test_validation_merge.merge(cat_days_since_prior(test_days_since_prior), how='left',\n",
        "                                                    left_on=['catid', 'days_since_prior_order'],\n",
        "                                                    right_on=['catid', 'days_since_prior_order'])\n",
        "test_validation_merge = test_validation_merge.merge(class_days_since_prior(test_days_since_prior), how='left',\n",
        "                                                    left_on=['classid', 'days_since_prior_order'],\n",
        "                                                    right_on=['classid', 'days_since_prior_order'])\n",
        "\n",
        "# user days since prior\n",
        "train_validation_merge = train_validation_merge.merge(user_days_since_prior(train_days_since_prior), how='left',\n",
        "                                                      left_on=['cid', 'days_since_prior_order'],\n",
        "                                                      right_on=['cid', 'days_since_prior_order'])\n",
        "\n",
        "test_validation_merge = test_validation_merge.merge(user_days_since_prior(test_days_since_prior), how='left',\n",
        "                                                    left_on=['cid', 'days_since_prior_order'],\n",
        "                                                    right_on=['cid', 'days_since_prior_order'])\n",
        "# up/ut/uc\n",
        "# train_validation_merge = train_validation_merge.merge(u_p_days_since_prior(train_days_since_prior), how='left',\n",
        "#                                                       left_on=[\"cid\", \"iid\", \"days_since_prior_order\"],\n",
        "#                                                       right_on=[\"cid\", \"iid\", \"days_since_prior_order\"])\n",
        "train_validation_merge = train_validation_merge.merge(u_t_days_since_prior(train_days_since_prior), how='left',\n",
        "                                                      left_on=[\"cid\", \"catid\", \"days_since_prior_order\"],\n",
        "                                                      right_on=[\"cid\", \"catid\", \"days_since_prior_order\"])\n",
        "train_validation_merge = train_validation_merge.merge(u_c_days_since_prior(train_days_since_prior), how='left',\n",
        "                                                      left_on=[\"cid\", \"classid\", \"days_since_prior_order\"],\n",
        "                                                      right_on=[\"cid\", \"classid\", \"days_since_prior_order\"])\n",
        "\n",
        "# test_validation_merge = test_validation_merge.merge(u_p_days_since_prior(test_days_since_prior), how='left',\n",
        "#                                                     left_on=[\"cid\", \"iid\", \"days_since_prior_order\"],\n",
        "#                                                     right_on=[\"cid\", \"iid\", \"days_since_prior_order\"])\n",
        "test_validation_merge = test_validation_merge.merge(u_t_days_since_prior(test_days_since_prior), how='left',\n",
        "                                                    left_on=[\"cid\", \"catid\", \"days_since_prior_order\"],\n",
        "                                                    right_on=[\"cid\", \"catid\", \"days_since_prior_order\"])\n",
        "test_validation_merge = test_validation_merge.merge(u_c_days_since_prior(test_days_since_prior), how='left',\n",
        "                                                    left_on=[\"cid\", \"classid\", \"days_since_prior_order\"],\n",
        "                                                    right_on=[\"cid\", \"classid\", \"days_since_prior_order\"])\n",
        "\n",
        "# merge product feature\n",
        "# train_validation_merge = train_validation_merge.merge(product_features_n_2, on='catid')\n",
        "# test_validation_merge = test_validation_merge.merge(product_features_n_1, on='catid')\n",
        "\n",
        "# merge cat feature\n",
        "train_validation_merge = train_validation_merge.merge(cat_features_n_2, on='catid')\n",
        "test_validation_merge = test_validation_merge.merge(cat_features_n_1, on='catid')\n",
        "\n",
        "# merge user product feature\n",
        "# train_validation_merge = train_validation_merge.merge(user_product_features_n_2, on=['cid', 'iid'])\n",
        "# test_validation_merge = test_validation_merge.merge(user_product_features_n_1, on=['cid', 'iid'])\n",
        "\n",
        "# merge user cat feature\n",
        "train_validation_merge = train_validation_merge.merge(user_cat_features_n_2, on=['cid', 'catid'])\n",
        "train_validation_merge.fillna(0, inplace=True)\n",
        "test_validation_merge = test_validation_merge.merge(user_cat_features_n_1, on=['cid', 'catid'])\n",
        "test_validation_merge.fillna(0, inplace=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%html\n",
        "<!DOCTYPE html><html><body align=\"right\"><br><div style=\"direction:;ltr\"><p style=\"background-color: #F7FFCA; color:black; border:1px solid black; border-radius: 10px; font-size:32px; line-height:1.8; font-family: byekan; text-align:justify; padding-left: 50px; padding-right: 50px; padding: 15px;\" >\n",
        "Save Prepared Data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "id": "jSn02H__1HdK",
        "outputId": "3e0b8a8b-5db0-4005-8bf2-3ac3d39d43d2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<!DOCTYPE html><html><body align=\"right\"><br><div style=\"direction:;ltr\"><p style=\"background-color: #F7FFCA; color:black; border:1px solid black; border-radius: 10px; font-size:32px; line-height:1.8; font-family: byekan; text-align:justify; padding-left: 50px; padding-right: 50px; padding: 15px;\" >\n",
              "Save Prepared Data\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N8VY0DBu8LOJ"
      },
      "outputs": [],
      "source": [
        "train_validation_merge.to_csv('train_validation_merge_v2.csv')\n",
        "test_validation_merge.to_csv('test_validation_merge_v2.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dwNNmTWcNiTu"
      },
      "outputs": [],
      "source": [
        "# train_validation_merge = pd.read_csv('train_validation_merge_v2.csv',index_col=0)\n",
        "# test_validation_merge = pd.read_csv('test_validation_merge_v2.csv',index_col=0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nwThquHGXdMm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FGeeETRDXeBG"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}