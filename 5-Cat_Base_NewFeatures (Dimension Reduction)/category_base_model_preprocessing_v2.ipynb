{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aC8YDqDC-f51",
        "outputId": "65fb0ff2-aadf-4da0-ef3f-422536040648"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y2iAYCd5AZ1A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e40e4bf-561a-4d11-ce6e-98744aa9c3af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/BC_Project\n"
          ]
        }
      ],
      "source": [
        "cd '/content/drive/My Drive/BC_Project/'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%html\n",
        "<!DOCTYPE html><html><body align=\"right\"><br><div style=\"direction:;ltr\"><p style=\"background-color: #F7FFCA; color:black; border:1px solid black; border-radius: 10px; font-size:32px; line-height:1.8; font-family: byekan; text-align:justify; padding-left: 50px; padding-right: 50px; padding: 15px;\" >\n",
        "Import libraries"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "id": "5EEg8StM6pbv",
        "outputId": "82e15b78-95a2-4aaf-f36d-4507ad474371"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<!DOCTYPE html><html><body align=\"right\"><br><div style=\"direction:;ltr\"><p style=\"background-color: #F7FFCA; color:black; border:1px solid black; border-radius: 10px; font-size:32px; line-height:1.8; font-family: byekan; text-align:justify; padding-left: 50px; padding-right: 50px; padding: 15px;\" >\n",
              "Import libraries\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "afDdlR_1Aabz"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from sklearn.decomposition import NMF\n",
        "from sklearn.preprocessing import normalize"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%html\n",
        "<!DOCTYPE html><html><body align=\"right\"><br><div style=\"direction:;ltr\"><p style=\"background-color: #F7FFCA; color:black; border:1px solid black; border-radius: 10px; font-size:32px; line-height:1.8; font-family: byekan; text-align:justify; padding-left: 50px; padding-right: 50px; padding: 15px;\" >\n",
        "Import Class table  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "id": "g11YaUzh6rvE",
        "outputId": "b8c2b05d-e424-4c6f-c235-e33e692fbe11"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<!DOCTYPE html><html><body align=\"right\"><br><div style=\"direction:;ltr\"><p style=\"background-color: #F7FFCA; color:black; border:1px solid black; border-radius: 10px; font-size:32px; line-height:1.8; font-family: byekan; text-align:justify; padding-left: 50px; padding-right: 50px; padding: 15px;\" >\n",
              "Import Class table  \n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y-VDi4atB0eC"
      },
      "outputs": [],
      "source": [
        "#read class DataFrame and set its columns' names\n",
        "class_df = pd.read_csv('CLASS.csv')\n",
        "class_df=class_df.rename(columns={\"id\":\"classid\",\"name\":\"class_name\"})\n",
        "class_df=class_df.drop_duplicates()\n",
        "\n",
        "#assign classes with no parent to primary parents\n",
        "class_df.loc[[1],'primaryparentid'] = 1\n",
        "class_df.loc[[18],'primaryparentid'] = 42\n",
        "class_df.loc[[28],'primaryparentid'] = 1\n",
        "class_df.loc[[34],'primaryparentid'] = 125\n",
        "class_df.loc[[35],'primaryparentid'] = 94\n",
        "class_df.loc[[101],'primaryparentid'] = 93\n",
        "class_df.loc[[102],'primaryparentid'] = 16\n",
        "class_df.loc[[103,104,184],'primaryparentid'] = 103"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%html\n",
        "<!DOCTYPE html><html><body align=\"right\"><br><div style=\"direction:;ltr\"><p style=\"background-color: #F7FFCA; color:black; border:1px solid black; border-radius: 10px; font-size:32px; line-height:1.8; font-family: byekan; text-align:justify; padding-left: 50px; padding-right: 50px; padding: 15px;\" >\n",
        "Import Order table"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "id": "L7l6sGtE6zJ5",
        "outputId": "965ecbca-5dd4-4862-cf54-8aef7a758ab8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<!DOCTYPE html><html><body align=\"right\"><br><div style=\"direction:;ltr\"><p style=\"background-color: #F7FFCA; color:black; border:1px solid black; border-radius: 10px; font-size:32px; line-height:1.8; font-family: byekan; text-align:justify; padding-left: 50px; padding-right: 50px; padding: 15px;\" >\n",
              "Import Order table\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "O2qViAJ6Hkqy",
        "outputId": "3d25ccec-1a5c-4984-bf99-eedb64f271ac"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" bid:    basket ID\\n    cid:    customer ID\\n    catid:  category ID\\n    iid:    item ID\\n    days:   days' count from that order\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "#read Orders DataFrame and set its columns' name.\n",
        "orders_df=pd.read_csv('ORDERS.csv')\n",
        "orders_df=orders_df.rename(columns={\"id\":\"bid\",\"id.1\":\"cid\",\"id.2\":\"catid\",'categoryid':'classid',\"id.3\":\"iid\",\"quantitystepcount\":\"quantity\",\"totaloriginalprice\":\"price\",\"?column?\":\"days\"})\n",
        "\"\"\" bid:    basket ID\n",
        "    cid:    customer ID\n",
        "    catid:  category ID\n",
        "    iid:    item ID\n",
        "    days:   days' count from that order\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EVUINgSycYVF"
      },
      "outputs": [],
      "source": [
        "#drop some missing values that contains a small part of the dataset\n",
        "# delete rows that contain wrong valuesorders_df.dropna(subset = ['classid','catid','iid','quantity','price','marketid'],inplace = True)\n",
        "orders_df = orders_df[orders_df['price']>300]\n",
        "orders_df = orders_df[orders_df['quantity']>0]\n",
        "#fill rows with null segmentation label with \"unlabeled\"\n",
        "orders_df.fillna('unlabeled',inplace = True)\n",
        "# Convert DataFrame to a category base DataFrame\n",
        "orders_df=orders_df.groupby(['bid', 'cid', 'checkoutdate','classid','catid', 'segmentationlabel', 'days', 'marketid']).sum().reset_index().sort_values('checkoutdate',ascending=False)\n",
        "customer_order_count = orders_df.drop_duplicates(['cid', 'bid']).groupby('cid').size()\n",
        "orders_df = orders_df[orders_df['cid'].isin(customer_order_count[customer_order_count > 2].index)]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LJJKP4aPwStZ"
      },
      "outputs": [],
      "source": [
        "class_counts = orders_df.__deepcopy__().groupby('classid').count().reset_index()[['classid','bid']].rename(columns = {'bid':'rep'})\n",
        "(class_counts[ (class_counts['rep']<100)].merge(class_df)).merge(class_counts,left_on = 'primaryparentid',right_on = 'classid',how = \"left\")\n",
        "rare_items = class_counts[ (class_counts['rep']<25)]['classid']\n",
        "orders_df = orders_df[~orders_df.classid.isin(rare_items)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bUDiLpCn_D2V"
      },
      "outputs": [],
      "source": [
        "#change format of checkout date from string to time\n",
        "def str_to_date(row):\n",
        "    return datetime.strptime(row, \"%Y-%m-%d %H:%M:%S.%f\")\n",
        "orders_df['checkoutdate'] = orders_df['checkoutdate'].apply(str_to_date)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ceX96blv_Dz5"
      },
      "outputs": [],
      "source": [
        "#add two columns that show first-time purchasing related to class or category\n",
        "\n",
        "# cat_first_checkout\n",
        "cat_first_checkout = orders_df.groupby(['cid', 'catid'], as_index=False)['checkoutdate'].min()\n",
        "cat_first_checkout.rename(columns={'checkoutdate': 'cat_first_checkout'}, inplace=True)\n",
        "orders_df = orders_df.merge(cat_first_checkout, on=['cid', 'catid'])\n",
        "\n",
        "# class_first_checkout\n",
        "class_first_checkout = orders_df.groupby(['cid', 'classid'], as_index=False)['checkoutdate'].min()\n",
        "class_first_checkout.rename(columns={'checkoutdate': 'class_first_checkout'}, inplace=True)\n",
        "orders_df = orders_df.merge(class_first_checkout, on=['cid', 'classid'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k0q-swul_DxT"
      },
      "outputs": [],
      "source": [
        "#with these functions we check whether this item/category is reordered or not.\n",
        "#if it isn't first order, then the related column takes 1, otherwise 0\n",
        "def check_reordered_cat(row):\n",
        "    if row.checkoutdate == row.cat_first_checkout:\n",
        "        return 0\n",
        "    return 1\n",
        "\n",
        "\n",
        "def check_reordered_class(row):\n",
        "    if row.checkoutdate == row.class_first_checkout:\n",
        "        return 0\n",
        "    return 1\n",
        "\n",
        "\n",
        "def get_week_day(row):\n",
        "    return row.weekday()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KGDPFcp7_Duu"
      },
      "outputs": [],
      "source": [
        "\n",
        "orders_df['day_of_week'] = orders_df['checkoutdate'].apply(get_week_day)\n",
        "orders_df['cat_reordered'] = orders_df.apply(check_reordered_cat, axis=1)\n",
        "orders_df['class_reordered'] = orders_df.apply(check_reordered_class, axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%html\n",
        "<!DOCTYPE html><html><body align=\"right\"><br><div style=\"direction:;ltr\"><p style=\"background-color: #F7FFCA; color:black; border:1px solid black; border-radius: 10px; font-size:32px; line-height:1.8; font-family: byekan; text-align:justify; padding-left: 50px; padding-right: 50px; padding: 15px;\" >\n",
        "Set labels and split prior data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "id": "6ejuBa9_7ZMY",
        "outputId": "22405e49-2aa6-4db7-ca3c-6be87e5effe0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<!DOCTYPE html><html><body align=\"right\"><br><div style=\"direction:;ltr\"><p style=\"background-color: #F7FFCA; color:black; border:1px solid black; border-radius: 10px; font-size:32px; line-height:1.8; font-family: byekan; text-align:justify; padding-left: 50px; padding-right: 50px; padding: 15px;\" >\n",
              "Set labels and split prior data\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IqJ7TMNk_Dry"
      },
      "outputs": [],
      "source": [
        "# 1 for an item that is reordered in the last basket and 0 for otherwise\n",
        "\n",
        "def reordered_label(row):\n",
        "    if row.checkoutdate == row.last_basket_date:\n",
        "        return 1\n",
        "    return 0\n",
        "\n",
        "# split last basket for prediction and other for creating features\n",
        "\n",
        "def split_prior_data(orders_dff):\n",
        "    last_basket = orders_dff.groupby(['cid'], as_index=False)['days'].min()\n",
        "    last_basket.rename(columns={'days': 'prior_last_basket'}, inplace=True)\n",
        "    orders_dff = orders_dff.merge(last_basket, on=['cid'])\n",
        "\n",
        "    last_basket_date = orders_dff.groupby(['cid'], as_index=False)['checkoutdate'].max()\n",
        "    last_basket_date.rename(columns={'checkoutdate': 'last_basket_date'}, inplace=True)\n",
        "    orders_dff = orders_dff.merge(last_basket_date, on=['cid'])\n",
        "\n",
        "    orders_dff['days'] -= orders_dff['prior_last_basket']\n",
        "    orders_dff['prior_last_basket'] = 0\n",
        "\n",
        "    orders_dff.sort_values(by=['cid', 'checkoutdate'], inplace=True)\n",
        "    last_so_id = orders_dff.drop_duplicates(subset=['cid'], keep='last')\n",
        "    prior_data = orders_dff[~orders_dff['bid'].isin(last_so_id['bid'])]\n",
        "\n",
        "    train_validation_data = orders_dff\n",
        "    train_validation_data.sort_values(by=['cid', 'checkoutdate'], inplace=True)\n",
        "    train_validation_data = train_validation_data[(((train_validation_data['cat_reordered'] == 1) &\n",
        "                                                    (train_validation_data['checkoutdate'] ==\n",
        "                                                     train_validation_data['last_basket_date']))\n",
        "                                                   | (train_validation_data['checkoutdate'] !=\n",
        "                                                      train_validation_data['last_basket_date']))]\n",
        "    train_validation_data.drop_duplicates(inplace=True, subset=['cid', 'catid'], keep='last')\n",
        "    del train_validation_data['bid']\n",
        "    train_validation_data = train_validation_data.merge(last_so_id[['cid', 'bid']], on='cid')\n",
        "    train_validation_data['reorder_label'] = train_validation_data.apply(reordered_label, axis=1)\n",
        "\n",
        "    del prior_data['last_basket_date']\n",
        "    del prior_data['prior_last_basket']\n",
        "    return prior_data, train_validation_data[['cid', 'bid','catid', 'classid', 'reorder_label']]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "prior_data_n_1, test_validation_data = split_prior_data(orders_df.__deepcopy__())\n",
        "prior_data_n_2, train_validation_data = split_prior_data(prior_data_n_1.__deepcopy__())\n",
        "prior_data_n_3, train_validation_data_2 = split_prior_data(prior_data_n_2.__deepcopy__())\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%html\n",
        "<!DOCTYPE html><html><body align=\"right\"><br><div style=\"direction:;ltr\"><p style=\"background-color: #F7FFCA; color:black; border:1px solid black; border-radius: 10px; font-size:32px; line-height:1.8; font-family: byekan; text-align:justify; padding-left: 50px; padding-right: 50px; padding: 15px;\" >\n",
        "Generate Features"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "id": "_faFMld8_LZe",
        "outputId": "983cdd8c-968a-4212-9584-e6721a24d318"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<!DOCTYPE html><html><body align=\"right\"><br><div style=\"direction:;ltr\"><p style=\"background-color: #F7FFCA; color:black; border:1px solid black; border-radius: 10px; font-size:32px; line-height:1.8; font-family: byekan; text-align:justify; padding-left: 50px; padding-right: 50px; padding: 15px;\" >\n",
              "Generate Features\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZjiVKQzn_Doi"
      },
      "outputs": [],
      "source": [
        "\n",
        "# user feature\n",
        "def generate_user_features(prior_data):\n",
        "    user_features = pd.DataFrame(columns=['user_id'])\n",
        "    user_features['user_id'] = prior_data['cid'].sort_values().unique()\n",
        "    user_reorder_rate = prior_data.groupby([\"cid\", \"cat_reordered\"])['cat_reordered'].count().groupby(level=0).apply(\n",
        "        lambda x: x / float(x.sum())).reset_index(name='cat_reorder_rate')\n",
        "    user_reorder_rate = user_reorder_rate.pivot(index='cid', columns='cat_reordered', values=['cat_reorder_rate'])\n",
        "    user_reorder_rate = pd.DataFrame(user_reorder_rate.to_records())\n",
        "    user_reorder_rate.columns = ['user_id', '0', '1']\n",
        "    user_reorder_rate.set_index(\"user_id\", inplace=True)\n",
        "    user_reorder_rate.fillna(0, inplace=True)\n",
        "    user_reorder_rate.reset_index(inplace=True)\n",
        "    user_features['user_cat_reorder_rate'] = user_reorder_rate['1']\n",
        "\n",
        "    # Get count of all unique cat for every user\n",
        "    user_features['user_unique_cats'] = \\\n",
        "        prior_data.groupby([\"cid\"])['catid'].nunique().reset_index(name='unique')['unique']\n",
        "\n",
        "    # Get count of all cat ordered by user\n",
        "    user_features['user_total_cats'] = prior_data.groupby([\"cid\"])['catid'].size().reset_index(name='count')['count']\n",
        "\n",
        "    # Get mean cat per user = Average cart size of user\n",
        "    df = prior_data.groupby([\"cid\", \"bid\"])['catid'].count().reset_index(name='cart_size') \\\n",
        "        .groupby('cid')['cart_size'].mean().reset_index()\n",
        "    user_features['user_avg_cart_size'] = df['cart_size']\n",
        "\n",
        "    # Get average days between 2 orders for every user\n",
        "    df = \\\n",
        "        prior_data.groupby([\"cid\", \"bid\"])['days'].max().reset_index(name='days_of_orders') \\\n",
        "            .groupby('cid')['days_of_orders'].diff()\n",
        "    df = pd.DataFrame({'days_between_orders': -df})\n",
        "    df['user_id'] = list(prior_data.groupby([\"cid\", \"bid\"])['days'].max().reset_index(level=0)['cid'])\n",
        "    df.dropna(inplace=True)\n",
        "    df = df.groupby('user_id', as_index=False)['days_between_orders'].mean()\n",
        "\n",
        "    user_features = user_features.merge(df, on='user_id')\n",
        "\n",
        "    # get user product reorder ratio\n",
        "    # number of unique products reordered / number of unique products ordered\n",
        "\n",
        "    # get user cats reorder ratio\n",
        "    # number of unique cats reordered / number of unique cats ordered\n",
        "\n",
        "    df = prior_data.groupby([\"cid\"])['catid'].nunique().reset_index(name='user_unique_cats')\n",
        "    df = df.merge(prior_data[prior_data['cat_reordered'] == 1].groupby([\"cid\"])['catid'].nunique().reset_index(\n",
        "        name='user_reordered_cats'), on='cid')\n",
        "    df.fillna(0, inplace=True)\n",
        "    df['user_reordered_cats_ratio'] = df['user_reordered_cats'] / df['user_unique_cats']\n",
        "    del user_features['user_unique_cats']\n",
        "    user_features = user_features.merge(df, left_on='user_id', right_on='cid')\n",
        "    del user_features['cid']\n",
        "\n",
        "    # get user classes reorder ratio\n",
        "    # number of unique classes reordered / number of unique classes ordered\n",
        "    df = prior_data.groupby([\"cid\"])['classid'].nunique().reset_index(name='user_unique_classes')\n",
        "    df = df.merge(prior_data[prior_data['cat_reordered'] == 1].groupby([\"cid\"])['classid'].nunique().reset_index(\n",
        "        name='user_reordered_classes'), on='cid')\n",
        "    df.fillna(0, inplace=True)\n",
        "    df['user_reordered_classes_ratio'] = df['user_reordered_classes'] / df['user_unique_classes']\n",
        "    user_features = user_features.merge(df, left_on='user_id', right_on='cid')\n",
        "    del user_features['cid']\n",
        "\n",
        "    return user_features\n",
        "\n",
        "\n",
        "user_features_n_1 = generate_user_features(prior_data_n_1)\n",
        "user_features_n_2 = generate_user_features(prior_data_n_2)\n",
        "user_features_n_3 = generate_user_features(prior_data_n_3)\n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yOY7a81P_QkD"
      },
      "outputs": [],
      "source": [
        "\n",
        "#  Cat Features :\n",
        "def generate_cat_features(prior_data):\n",
        "    # create an empty dataframe\n",
        "    product_features = pd.DataFrame(columns=['catid'])\n",
        "\n",
        "    # add cat_name\n",
        "    product_features['catid'] = prior_data['catid'].sort_values().unique()\n",
        "\n",
        "    ############# average days between cat reorder\n",
        "    df = prior_data.sort_values(by=['cid','catid','checkoutdate'])[['cid','bid','catid','checkoutdate','days','price']]\n",
        "    df['days_since_prior_cat_order']= -df.groupby(['cid', 'catid'])['days'].transform(lambda x: x.diff())\n",
        "    df3 = df.groupby(['catid']).mean().reset_index()[['catid','days_since_prior_cat_order']]\n",
        "    df3.fillna(df3.days_since_prior_cat_order.mean(),inplace = True)\n",
        "    df3.rename(columns = {'days_since_prior_cat_order':'days_between_cat_orders'},inplace = True)\n",
        "    days_to_next = list(df['days_since_prior_cat_order'].iloc[1:])\n",
        "    days_to_next.append(np.nan)\n",
        "    # df = \\\n",
        "    #     prior_data.groupby([\"cid\", \"bid\"])['days'].max().reset_index(name='days_of_orders') \\\n",
        "    #         .groupby('cid')['days_of_orders'].diff()\n",
        "    # df = pd.DataFrame({'days_between_orders': -df})\n",
        "    df['days_to_next_order'] = days_to_next\n",
        "    df['price'] = df['price'].astype(float)\n",
        "    df['days_to_next_order'] = df['days_to_next_order'].replace(0,1)\n",
        "    df['price_day_ratio']=df['price']/df['days_to_next_order']\n",
        "    df.loc[abs(df['days_to_next_order'])==0, \"price_day_ratio\"] = np.nan\n",
        "    df2=df.groupby([\"catid\"])['price_day_ratio'].mean().reset_index(name='ave_price_day_ratio')\n",
        "    # df2.fillna(0, inplace=True)\n",
        "    product_features=product_features.merge(df2,on=['catid'])\n",
        "    product_features=product_features.merge(df3,on=['catid'])\n",
        "    ###############################\n",
        "\n",
        "    # get reorder_rate for each cat\n",
        "    # reorder_rate = reorders / total orders\n",
        "    df = pd.DataFrame({'cat_reorder_rate': prior_data.groupby(['catid', 'cat_reordered'])['cat_reordered'].\\\n",
        "                      count().groupby(level=0).apply(lambda x: x / float(x.sum()))}).reset_index()\n",
        "\n",
        "    # get data of reordered cat only\n",
        "    new_df = df[df['cat_reordered'] == 1]\n",
        "    new_df['cat_reorder_rate'] = new_df['cat_reorder_rate'] * new_df['cat_reordered']\n",
        "\n",
        "    # handling for cat which were never reordered, hence reorder_rate = 0.0\n",
        "    new_df_1 = df[(df['cat_reordered'] == 0) & (df['cat_reorder_rate'] == float(1.0))]\n",
        "    new_df_1['cat_reorder_rate'] = new_df_1['cat_reorder_rate'] * new_df_1['cat_reordered']\n",
        "    new_df = new_df.append(new_df_1)\n",
        "\n",
        "    # drop other columns of the new_df and sort values by cat name to align with cat features dataframe\n",
        "    new_df.drop('cat_reordered', axis=1, inplace=True)\n",
        "    new_df.sort_values(by='catid', inplace=True)\n",
        "    new_df = new_df.reset_index(drop=True)\n",
        "\n",
        "    # add to feat_1 of cat_features dataframe\n",
        "    product_features['cat_reorder_rate'] = new_df['cat_reorder_rate']\n",
        "\n",
        "    #  generate boolean values if cat belongs to below classes\n",
        "    products = orders_df[['catid', 'classid']].drop_duplicates().reset_index()\n",
        "\n",
        "\n",
        "\n",
        "    products['isMilk'] = products['classid'].apply(lambda x: x == 51).astype(int)\n",
        "    products['isSeifijat'] = products['classid'].apply(lambda x: x == 57).astype(int)\n",
        "    products['isFruits'] = products['classid'].apply(lambda x: x == 21).astype(int)\n",
        "    products['isLabaniat'] = products['classid'].apply(lambda x: x == 2 or x == 55).astype(int)\n",
        "    products['isProtein'] = products['classid'].apply(lambda x: x == 156 or x == 68).astype(int)\n",
        "    products['isSnack'] = products['classid'].apply(lambda x: x == 131 or x == 132 or x == 133).astype(int)\n",
        "    products['isKalayeAsasi'] = products['classid'].apply(\n",
        "        lambda x: x == 9 or x == 45 or x == 92 or x == 69 or x == 71).astype(int)\n",
        "\n",
        "    new_product_feat = products[\n",
        "        ['isMilk', 'isSeifijat', 'isFruits', 'isLabaniat', 'isProtein', 'isSnack', 'isKalayeAsasi']]\n",
        "\n",
        "    # reduce sparsity using NMF\n",
        "    # ref:https://www.kaggle.com/themissingsock/matrix-decomposition-with-buyer-data\n",
        "\n",
        "    nmf = NMF(n_components=3)\n",
        "    model = nmf.fit(new_product_feat)\n",
        "    W = model.transform(new_product_feat)\n",
        "    prod_data = pd.DataFrame(normalize(W))\n",
        "\n",
        "    prod_data.columns = ['p_reduced_feat_1', 'p_reduced_feat_2', 'p_reduced_feat_3']\n",
        "    products.drop(['isMilk', 'isSeifijat', 'isFruits', 'isLabaniat', 'isProtein', 'isSnack', 'isKalayeAsasi'],\n",
        "                  axis=1, inplace=True)\n",
        "\n",
        "    product_features['p_reduced_feat_1'] = prod_data['p_reduced_feat_1']\n",
        "    product_features['p_reduced_feat_2'] = prod_data['p_reduced_feat_2']\n",
        "    product_features['p_reduced_feat_3'] = prod_data['p_reduced_feat_3']\n",
        "\n",
        "    # merge dept_reorder_rate and aisle_reorder_rate to existing product features\n",
        "\n",
        "    del df, new_df, new_df_1, new_product_feat, model, prod_data\n",
        "    return product_features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QhilMXg9yx1u"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lmmwHsMX_Di_"
      },
      "outputs": [],
      "source": [
        "\n",
        "def generate_user_cat_features(prior_data):\n",
        "    # create an empty dataframe\n",
        "    user_cat_features = pd.DataFrame(columns=['cid', 'catid'])\n",
        "\n",
        "    # add user and cat to dataframe\n",
        "    u_t = prior_data.groupby([\"cid\", \"catid\"]).size().reset_index()\n",
        "    user_cat_features[\"cid\"] = u_t[\"cid\"]\n",
        "    user_cat_features[\"catid\"] = u_t[\"catid\"]\n",
        "\n",
        "    # How frequently user ordered the cat ?\n",
        "    # #times user ordered the cat/ #times user placed an order\n",
        "    df = prior_data.groupby([\"cid\", \"catid\"])[\"cat_reordered\"].size()\n",
        "    df = df / prior_data.groupby([\"cid\"]).size()\n",
        "    df = df.reset_index(name='order_rate')\n",
        "    df.fillna(0., inplace=True)\n",
        "    user_cat_features[\"u_t_order_rate\"] = df[\"order_rate\"]\n",
        "\n",
        "    # How frequently user reordered the cat ?\n",
        "    # #times user reordered the cat/ #times user ordered the cat\n",
        "    df = prior_data[prior_data[\"cat_reordered\"] == 1].groupby([\"cid\", \"catid\"])[\"cat_reordered\"].size()\n",
        "    df = df / prior_data.groupby([\"cid\", \"catid\"]).size()\n",
        "    df = df.reset_index(name='reorder_rate')\n",
        "    df.fillna(0., inplace=True)\n",
        "    user_cat_features[\"u_t_reorder_rate\"] = df[\"reorder_rate\"]\n",
        "\n",
        "    # Number of orders placed since the cat was last ordered ?\n",
        "\n",
        "    ############# average days between cat reorder\n",
        "    df = prior_data.sort_values(by=['cid','catid','checkoutdate'])[['cid','bid','catid','checkoutdate','days','price']]\n",
        "    df['days_since_prior_cat_order']= -df.groupby(['cid', 'catid'])['days'].transform(lambda x: x.diff())\n",
        "    df1 = df.groupby(['cid','catid']).mean().reset_index()[['cid','catid','days_since_prior_cat_order']]\n",
        "    df1.rename(columns = {'days_since_prior_cat_order':'days_between_user_cat_orders'},inplace = True)\n",
        "    days_to_next = list(df['days_since_prior_cat_order'].iloc[1:])\n",
        "    days_to_next.append(np.nan)\n",
        "    \n",
        "    df['days_to_next_order'] = days_to_next\n",
        "    df['price'] = df['price'].astype(float)\n",
        "    df['days_to_next_order'] = df['days_to_next_order'].replace(0,1)\n",
        "    df['price_day_ratio']=df['price']/df['days_to_next_order']\n",
        "    # df.loc[abs(df['days_to_next_order'])==0, \"price_day_ratio\"] = np.nan\n",
        "    df2=df.groupby([\"cid\", \"catid\"])['price_day_ratio'].mean().reset_index(name='user_ave_price_day_ratio')\n",
        "    # df2.fillna(0, inplace=True)\n",
        "    user_cat_features=user_cat_features.merge(df2,on=['cid','catid'])\n",
        "    user_cat_features=user_cat_features.merge(df1,on=['cid','catid'])\n",
        "\n",
        "    df = prior_data.sort_values(by=['cid','catid','checkoutdate'])[['cid','bid','catid','checkoutdate','days','price']].drop_duplicates(subset=['cid','catid'],keep='last')\n",
        "    df['price'] = df['price'].astype(float)\n",
        "    df['user_days_price_ratio_since_prior']=df['price']/(df['days']+0.4)\n",
        "    user_cat_features=user_cat_features.merge(df[['cid','catid','user_days_price_ratio_since_prior']],on=['cid','catid'])\n",
        "\n",
        "    ###############################3\n",
        "\n",
        "\n",
        "    #  Get Number of orders\n",
        "    prior_data_order_number = prior_data.groupby('cid').apply(\n",
        "        lambda x: x.drop_duplicates(subset='bid').reset_index(drop=True).\n",
        "            reset_index()[['cid', 'bid', 'index']].merge(x, on=['cid', 'bid'])).reset_index(drop=True)\n",
        "\n",
        "    prior_data_order_number = prior_data_order_number.rename({'index': 'order_number'}, axis='columns')\n",
        "\n",
        "\n",
        "\n",
        "    # Get last order_number placed by user , subtract with last order_number with the CAT in cart\n",
        "    df = prior_data_order_number.groupby([\"cid\", \"catid\"])['order_number'].max().reset_index()\n",
        "    df_2 = prior_data_order_number.groupby([\"cid\"])['order_number'].max().reset_index()\n",
        "    new_df = pd.merge(df, df_2, how='outer', left_on=['cid'], right_on=['cid'])\n",
        "    new_df['order_number_diff'] = new_df['order_number_y'] - new_df['order_number_x']\n",
        "    user_cat_features['u_t_orders_since_last'] = new_df['order_number_diff']\n",
        "\n",
        "    # Get last order_number placed by user , subtract with last order_number with the CLASS in cart\n",
        "    df = prior_data_order_number.groupby([\"cid\", \"classid\"])['order_number'].max().reset_index()\n",
        "    df_2 = prior_data_order_number.groupby([\"cid\"])['order_number'].max().reset_index()\n",
        "    new_df = pd.merge(df, df_2, how='outer', left_on=['cid'], right_on=['cid'])\n",
        "    new_df['order_number_diff'] = new_df['order_number_y'] - new_df['order_number_x']\n",
        "    user_cat_features['u_c_orders_since_last'] = new_df['order_number_diff']\n",
        "\n",
        "    # max_streak\n",
        "    def max_streak(row):\n",
        "        #  Function to calculate the maximum number of orders in a row which contains reorders of a cat\n",
        "        maxx = 0\n",
        "        summ = 0\n",
        "        for i in range(len(row) - 1):\n",
        "            if row[i + 1] - row[i] == 1:\n",
        "                summ += 1\n",
        "            else:\n",
        "                if summ > maxx:\n",
        "                    maxx = summ\n",
        "                summ = 0\n",
        "        return maxx\n",
        "\n",
        "    df = prior_data_order_number.groupby([\"cid\", \"catid\"])['order_number'].apply(list).reset_index(name='max_streak_cat')\n",
        "\n",
        "    df['max_streak_cat'] = [max_streak(df['max_streak_cat'].iloc[i]) for i in range(len(df))]\n",
        "    user_product_features = pd.merge(user_cat_features, df, on=[\"cid\", \"catid\"])\n",
        "\n",
        "    del df, prior_data_order_number , df2 ,df_2\n",
        "    return user_product_features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d5VxI79m_Ddc"
      },
      "outputs": [],
      "source": [
        "cat_features_n_1 = generate_cat_features(prior_data_n_1)\n",
        "cat_features_n_2 = generate_cat_features(prior_data_n_2)\n",
        "cat_features_n_3 = generate_cat_features(prior_data_n_3)\n",
        "\n",
        "user_cat_features_n_1 = generate_user_cat_features(prior_data_n_1)\n",
        "user_cat_features_n_2 = generate_user_cat_features(prior_data_n_2)\n",
        "user_cat_features_n_3 = generate_user_cat_features(prior_data_n_3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rTk3y3L4Sf7W",
        "outputId": "f2de0bf5-2719-4d90-d752-b5ec02ddafb5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(0, 10)\n",
            "(0, 10)\n",
            "(0, 10)\n",
            "(0, 10)\n",
            "(0, 10)\n",
            "(0, 10)\n",
            "(0, 7)\n",
            "(0, 7)\n",
            "(0, 7)\n"
          ]
        }
      ],
      "source": [
        "#number of zero values \n",
        "print(user_cat_features_n_1[user_cat_features_n_1['user_ave_price_day_ratio']==0].shape)\n",
        "print(user_cat_features_n_2[user_cat_features_n_2['user_ave_price_day_ratio']==0].shape)\n",
        "print(user_cat_features_n_3[user_cat_features_n_3['user_ave_price_day_ratio']==0].shape)\n",
        "print(user_cat_features_n_1[user_cat_features_n_1['user_days_price_ratio_since_prior']==0].shape)\n",
        "print(user_cat_features_n_2[user_cat_features_n_2['user_days_price_ratio_since_prior']==0].shape)\n",
        "print(user_cat_features_n_3[user_cat_features_n_3['user_days_price_ratio_since_prior']==0].shape)\n",
        "print(cat_features_n_1[cat_features_n_1['ave_price_day_ratio']==0].shape)\n",
        "print(cat_features_n_2[cat_features_n_2['ave_price_day_ratio']==0].shape)\n",
        "print(cat_features_n_3[cat_features_n_3['ave_price_day_ratio']==0].shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#number of infinity values\n",
        "print(user_cat_features_n_1[user_cat_features_n_1['user_days_price_ratio_since_prior'].isin([np.inf,-np.inf])].shape)\n",
        "print(user_cat_features_n_2[user_cat_features_n_2['user_days_price_ratio_since_prior'].isin([np.inf,-np.inf])].shape)\n",
        "print(user_cat_features_n_3[user_cat_features_n_3['user_days_price_ratio_since_prior'].isin([np.inf,-np.inf])].shape)\n",
        "print(user_cat_features_n_1[user_cat_features_n_1['user_ave_price_day_ratio'].isin([np.inf,-np.inf])].shape)\n",
        "print(user_cat_features_n_2[user_cat_features_n_2['user_ave_price_day_ratio'].isin([np.inf,-np.inf])].shape)\n",
        "print(user_cat_features_n_3[user_cat_features_n_3['user_ave_price_day_ratio'].isin([np.inf,-np.inf])].shape)\n",
        "print(cat_features_n_1[cat_features_n_1['ave_price_day_ratio'].isin([np.inf,-np.inf])].shape)\n",
        "print(cat_features_n_2[cat_features_n_2['ave_price_day_ratio'].isin([np.inf,-np.inf])].shape)\n",
        "print(cat_features_n_3[cat_features_n_3['ave_price_day_ratio'].isin([np.inf,-np.inf])].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Kybrste7DSC",
        "outputId": "26258b0b-54e9-400f-9bc3-341ee19630ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(0, 10)\n",
            "(0, 10)\n",
            "(0, 10)\n",
            "(0, 10)\n",
            "(0, 10)\n",
            "(0, 10)\n",
            "(0, 7)\n",
            "(0, 7)\n",
            "(0, 7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "a6qiGV3h7AyM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SEm7lYlnMmFh"
      },
      "outputs": [],
      "source": [
        "#replace zero by one (avoiding creating infinity)\n",
        "cat_features_n_1['days_between_cat_orders'] = cat_features_n_1['days_between_cat_orders'].replace(0,1)  \n",
        "cat_features_n_2['days_between_cat_orders'] = cat_features_n_2['days_between_cat_orders'].replace(0,1)  \n",
        "cat_features_n_3['days_between_cat_orders'] = cat_features_n_3['days_between_cat_orders'].replace(0,1)  \n",
        "\n",
        "user_cat_features_n_1['days_between_user_cat_orders'] = user_cat_features_n_1['days_between_user_cat_orders'].replace(0,1)  \n",
        "user_cat_features_n_2['days_between_user_cat_orders'] = user_cat_features_n_2['days_between_user_cat_orders'].replace(0,1)  \n",
        "user_cat_features_n_3['days_between_user_cat_orders'] = user_cat_features_n_3['days_between_user_cat_orders'].replace(0,1)  \n",
        "\n",
        "user_features_n_1['days_between_orders'] = user_features_n_1['days_between_orders'].replace(0,1)  \n",
        "user_features_n_2['days_between_orders'] = user_features_n_2['days_between_orders'].replace(0,1)  \n",
        "user_features_n_3['days_between_orders'] = user_features_n_3['days_between_orders'].replace(0,1) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "afqnhNFO_Dam"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "feature : how frequently product was reordered on any given hour ?\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def cat_day(prior_data):\n",
        "    df = prior_data.groupby(['catid', 'day_of_week'])[\"cat_reordered\"].size()\n",
        "    df = df / prior_data.groupby([\"catid\"]).size()\n",
        "    df = df.reset_index(name='cat_week_reorder_rate')\n",
        "    return df\n",
        "\n",
        "\n",
        "def class_day(prior_data):\n",
        "    df = prior_data.groupby(['classid', 'day_of_week'])[\"class_reordered\"].size()\n",
        "    df = df / prior_data.groupby([\"classid\"]).size()\n",
        "    df = df.reset_index(name='class_week_reorder_rate')\n",
        "    return df\n",
        "\n",
        "\n",
        "def get_days_since_prior(orders_df):\n",
        "    customer_order_days = orders_df.sort_values(by='checkoutdate').groupby([\"cid\", \"bid\"], as_index=False)['days'].max()\n",
        "    df = customer_order_days.groupby(['cid']).diff()['days']\n",
        "    df = pd.DataFrame({'days_since_prior_order': -df})\n",
        "    df[['cid', 'bid']] = customer_order_days[['cid', 'bid']]\n",
        "    df.dropna(inplace=True)\n",
        "    df['days_since_prior_order'] = df['days_since_prior_order'].astype(int)\n",
        "    days_since_prior = df.merge(orders_df, on=['cid', 'bid'])\n",
        "    return days_since_prior\n",
        "\n",
        "# last_cid_so_prior = days_since_prior.drop_duplicates(subset=['cid'], keep='last')\n",
        "\n",
        "\n",
        "\n",
        "test_days_since_prior = get_days_since_prior(orders_df.__deepcopy__())\n",
        "train_days_since_prior = get_days_since_prior(prior_data_n_1.__deepcopy__())\n",
        "train_days_since_prior_2 = get_days_since_prior(prior_data_n_2.__deepcopy__())\n",
        "\n",
        "train_validation_data = train_validation_data.merge(train_days_since_prior[['cid', 'bid', 'days_since_prior_order',\n",
        "                                                                            'day_of_week', 'checkoutdate']],\n",
        "                                                    on=['cid', 'bid'])\n",
        "train_validation_data_2 = train_validation_data_2.merge(train_days_since_prior_2[['cid', 'bid', 'days_since_prior_order',\n",
        "                                                                            'day_of_week', 'checkoutdate']],\n",
        "                                                    on=['cid', 'bid'])\n",
        "\n",
        "train_validation_data.drop_duplicates(inplace=True)\n",
        "train_days_since_prior = train_days_since_prior[~train_days_since_prior['bid'].isin(train_validation_data['bid'])]\n",
        "train_validation_data_2.drop_duplicates(inplace=True)\n",
        "train_days_since_prior_2 = train_days_since_prior_2[~train_days_since_prior_2['bid'].isin(train_validation_data_2['bid'])]\n",
        "\n",
        "test_validation_data = test_validation_data.merge(\n",
        "    test_days_since_prior[['cid', 'bid', 'days_since_prior_order', 'day_of_week', 'checkoutdate']],\n",
        "    on=['cid', 'bid'])\n",
        "test_validation_data.drop_duplicates(inplace=True)\n",
        "test_days_since_prior = test_days_since_prior[~test_days_since_prior['bid'].isin(test_validation_data['bid'])]\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kleoUoFs_DX4"
      },
      "outputs": [],
      "source": [
        "\n",
        "def cat_days_since_prior(days_since_prior):\n",
        "    df = days_since_prior.groupby(['catid', 'days_since_prior_order'])[\"cat_reordered\"].size()\n",
        "    df = df / days_since_prior.groupby([\"catid\"]).size()\n",
        "    df = df.reset_index(name='t_days_since_prior_order_reorder_rate')\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "def class_days_since_prior(days_since_prior):\n",
        "    df = days_since_prior.groupby(['classid', 'days_since_prior_order'])[\"class_reordered\"].size()\n",
        "    df = df / days_since_prior.groupby([\"classid\"]).size()\n",
        "    df = df.reset_index(name='c_days_since_prior_order_reorder_rate')\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "def user_days_since_prior(days_since_prior):\n",
        "    \"\"\"\n",
        "    feature: how frequently user reordered any product given difference between 2 orders in days ?\n",
        "    \"\"\"\n",
        "    df = days_since_prior.groupby(['cid', 'days_since_prior_order'])[\"cat_reordered\"].size()\n",
        "    df = df / days_since_prior.groupby([\"cid\"]).size()\n",
        "    df = df.reset_index(name='u_days_since_prior_order_reorder_rate')\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def u_t_days_since_prior(days_since_prior):\n",
        "    df = days_since_prior.groupby([\"cid\", \"catid\", \"days_since_prior_order\"])[\"cat_reordered\"].size()\n",
        "    df = df / days_since_prior.groupby([\"cid\", \"catid\"]).size()\n",
        "    df = df.reset_index(name='u_t_days_since_prior_reorder_rate')\n",
        "    return df\n",
        "\n",
        "\n",
        "def u_c_days_since_prior(days_since_prior):\n",
        "    df = days_since_prior.groupby([\"cid\", \"classid\", \"days_since_prior_order\"])[\"class_reordered\"].size()\n",
        "    df = df / days_since_prior.groupby([\"cid\", \"classid\"]).size()\n",
        "    df = df.reset_index(name='u_c_days_since_prior_reorder_rate')\n",
        "    return df\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vwk0zrp9TziA"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "brAPb1-0_DU2"
      },
      "outputs": [],
      "source": [
        "\n",
        "# merge features\n",
        "train_validation_merge_1 = train_validation_data.merge(user_features_n_2, left_on='cid', right_on='user_id')\n",
        "# train_validation_merge_1 = train_validation_merge_1.merge(product_day(train_days_since_prior), how='left',\n",
        "#                                                       on=['iid', 'day_of_week'])\n",
        "train_validation_merge_1 = train_validation_merge_1.merge(cat_day(train_days_since_prior), how='left',\n",
        "                                                      on=['catid', 'day_of_week'])\n",
        "train_validation_merge_1 = train_validation_merge_1.merge(class_day(train_days_since_prior), how='left',\n",
        "                                                      on=['classid', 'day_of_week'])\n",
        "\n",
        "train_validation_merge_2 = train_validation_data_2.merge(user_features_n_3, left_on='cid', right_on='user_id')\n",
        "# train_validation_merge_1 = train_validation_merge_1.merge(product_day(train_days_since_prior_2), how='left',\n",
        "#                                                       on=['iid', 'day_of_week'])\n",
        "train_validation_merge_2 = train_validation_merge_2.merge(cat_day(train_days_since_prior_2), how='left',\n",
        "                                                      on=['catid', 'day_of_week'])\n",
        "train_validation_merge_2 = train_validation_merge_2.merge(class_day(train_days_since_prior_2), how='left',\n",
        "                                                      on=['classid', 'day_of_week'])\n",
        "\n",
        "test_validation_merge = test_validation_data.merge(user_features_n_1, left_on='cid', right_on='user_id')\n",
        "# test_validation_merge = test_validation_merge.merge(product_day(test_days_since_prior), how='left',\n",
        "#                                                     on=['iid', 'day_of_week'])\n",
        "test_validation_merge = test_validation_merge.merge(cat_day(test_days_since_prior), how='left',\n",
        "                                                    on=['catid', 'day_of_week'])\n",
        "test_validation_merge = test_validation_merge.merge(class_day(test_days_since_prior), how='left',\n",
        "                                                    on=['classid', 'day_of_week'])\n",
        "################################\n",
        "\n",
        "# product/cat/class\n",
        "# train_validation_merge_1 = train_validation_merge_1.merge(product_days_since_prior(train_days_since_prior), how='left',\n",
        "#                                                       left_on=['iid', 'days_since_prior_order'],\n",
        "#                                                       right_on=['iid', 'days_since_prior_order'])\n",
        "train_validation_merge_1 = train_validation_merge_1.merge(cat_days_since_prior(train_days_since_prior), how='left',\n",
        "                                                      left_on=['catid', 'days_since_prior_order'],\n",
        "                                                      right_on=['catid', 'days_since_prior_order'])\n",
        "train_validation_merge_1 = train_validation_merge_1.merge(class_days_since_prior(train_days_since_prior), how='left',\n",
        "                                                      left_on=['classid', 'days_since_prior_order'],\n",
        "                                                      right_on=['classid', 'days_since_prior_order'])\n",
        "\n",
        "# train_validation_merge_2 = train_validation_merge_2.merge(product_days_since_prior(train_days_since_prior_2), how='left',\n",
        "#                                                       left_on=['iid', 'days_since_prior_order'],\n",
        "#                                                       right_on=['iid', 'days_since_prior_order'])\n",
        "train_validation_merge_2 = train_validation_merge_2.merge(cat_days_since_prior(train_days_since_prior_2), how='left',\n",
        "                                                      left_on=['catid', 'days_since_prior_order'],\n",
        "                                                      right_on=['catid', 'days_since_prior_order'])\n",
        "train_validation_merge_2 = train_validation_merge_2.merge(class_days_since_prior(train_days_since_prior_2), how='left',\n",
        "                                                      left_on=['classid', 'days_since_prior_order'],\n",
        "                                                      right_on=['classid', 'days_since_prior_order'])\n",
        "\n",
        "# test_validation_merge = test_validation_merge.merge(product_days_since_prior(test_days_since_prior), how='left',\n",
        "#                                                     left_on=['iid', 'days_since_prior_order'],\n",
        "#                                                     right_on=['iid', 'days_since_prior_order'])\n",
        "test_validation_merge = test_validation_merge.merge(cat_days_since_prior(test_days_since_prior), how='left',\n",
        "                                                    left_on=['catid', 'days_since_prior_order'],\n",
        "                                                    right_on=['catid', 'days_since_prior_order'])\n",
        "test_validation_merge = test_validation_merge.merge(class_days_since_prior(test_days_since_prior), how='left',\n",
        "                                                    left_on=['classid', 'days_since_prior_order'],\n",
        "                                                    right_on=['classid', 'days_since_prior_order'])\n",
        "\n",
        "################################\n",
        "# user days since prior\n",
        "train_validation_merge_1 = train_validation_merge_1.merge(user_days_since_prior(train_days_since_prior), how='left',\n",
        "                                                      left_on=['cid', 'days_since_prior_order'],\n",
        "                                                      right_on=['cid', 'days_since_prior_order'])\n",
        "\n",
        "train_validation_merge_2 = train_validation_merge_2.merge(user_days_since_prior(train_days_since_prior_2), how='left',\n",
        "                                                      left_on=['cid', 'days_since_prior_order'],\n",
        "                                                      right_on=['cid', 'days_since_prior_order'])\n",
        "\n",
        "test_validation_merge = test_validation_merge.merge(user_days_since_prior(test_days_since_prior), how='left',\n",
        "                                                    left_on=['cid', 'days_since_prior_order'],\n",
        "                                                    right_on=['cid', 'days_since_prior_order'])\n",
        "################################\n",
        "# up/ut/uc\n",
        "# train_validation_merge_1 = train_validation_merge_1.merge(u_p_days_since_prior(train_days_since_prior), how='left',\n",
        "#                                                       left_on=[\"cid\", \"iid\", \"days_since_prior_order\"],\n",
        "#                                                       right_on=[\"cid\", \"iid\", \"days_since_prior_order\"])\n",
        "train_validation_merge_1 = train_validation_merge_1.merge(u_t_days_since_prior(train_days_since_prior), how='left',\n",
        "                                                      left_on=[\"cid\", \"catid\", \"days_since_prior_order\"],\n",
        "                                                      right_on=[\"cid\", \"catid\", \"days_since_prior_order\"])\n",
        "train_validation_merge_1 = train_validation_merge_1.merge(u_c_days_since_prior(train_days_since_prior), how='left',\n",
        "                                                      left_on=[\"cid\", \"classid\", \"days_since_prior_order\"],\n",
        "                                                      right_on=[\"cid\", \"classid\", \"days_since_prior_order\"])\n",
        "\n",
        "# train_validation_merge_2 = train_validation_merge_2.merge(u_p_days_since_prior(train_days_since_prior), how='left',\n",
        "#                                                       left_on=[\"cid\", \"iid\", \"days_since_prior_order\"],\n",
        "#                                                       right_on=[\"cid\", \"iid\", \"days_since_prior_order\"])\n",
        "train_validation_merge_2 = train_validation_merge_2.merge(u_t_days_since_prior(train_days_since_prior_2), how='left',\n",
        "                                                      left_on=[\"cid\", \"catid\", \"days_since_prior_order\"],\n",
        "                                                      right_on=[\"cid\", \"catid\", \"days_since_prior_order\"])\n",
        "train_validation_merge_2 = train_validation_merge_2.merge(u_c_days_since_prior(train_days_since_prior_2), how='left',\n",
        "                                                      left_on=[\"cid\", \"classid\", \"days_since_prior_order\"],\n",
        "                                                      right_on=[\"cid\", \"classid\", \"days_since_prior_order\"])\n",
        "\n",
        "\n",
        "# test_validation_merge = test_validation_merge.merge(u_p_days_since_prior(test_days_since_prior), how='left',\n",
        "#                                                     left_on=[\"cid\", \"iid\", \"days_since_prior_order\"],\n",
        "#                                                     right_on=[\"cid\", \"iid\", \"days_since_prior_order\"])\n",
        "test_validation_merge = test_validation_merge.merge(u_t_days_since_prior(test_days_since_prior), how='left',\n",
        "                                                    left_on=[\"cid\", \"catid\", \"days_since_prior_order\"],\n",
        "                                                    right_on=[\"cid\", \"catid\", \"days_since_prior_order\"])\n",
        "test_validation_merge = test_validation_merge.merge(u_c_days_since_prior(test_days_since_prior), how='left',\n",
        "                                                    left_on=[\"cid\", \"classid\", \"days_since_prior_order\"],\n",
        "                                                    right_on=[\"cid\", \"classid\", \"days_since_prior_order\"])\n",
        "#############################\n",
        "# merge product feature\n",
        "# train_validation_merge_1 = train_validation_merge_1.merge(product_features_n_2, on='catid')\n",
        "# test_validation_merge = test_validation_merge.merge(product_features_n_1, on='catid')\n",
        "#############################\n",
        "# merge cat feature\n",
        "train_validation_merge_1 = train_validation_merge_1.merge(cat_features_n_2, on='catid')\n",
        "train_validation_merge_2 = train_validation_merge_2.merge(cat_features_n_3, on='catid')\n",
        "test_validation_merge = test_validation_merge.merge(cat_features_n_1, on='catid')\n",
        "#############################\n",
        "# merge user product feature\n",
        "# train_validation_merge = train_validation_merge_1.merge(user_product_features_n_2, on=['cid', 'iid'])\n",
        "# test_validation_merge = test_validation_merge.merge(user_product_features_n_1, on=['cid', 'iid'])\n",
        "#############################\n",
        "# merge user cat feature\n",
        "train_validation_merge_1 = train_validation_merge_1.merge(user_cat_features_n_2, on=['cid', 'catid'])\n",
        "train_validation_merge_2 = train_validation_merge_2.merge(user_cat_features_n_3, on=['cid', 'catid'])\n",
        "test_validation_merge = test_validation_merge.merge(user_cat_features_n_1, on=['cid', 'catid'])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cOk0cPC5ANmx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#handle missing values of new features \n",
        "mean_ave_price_day_ratio = train_validation_merge_1['ave_price_day_ratio'].mean() \n",
        "train_validation_merge_1['ave_price_day_ratio'] = mean_ave_price_day_ratio\n",
        "train_validation_merge_2['ave_price_day_ratio'] = mean_ave_price_day_ratio\n",
        "test_validation_merge['ave_price_day_ratio'] = mean_ave_price_day_ratio\n",
        "\n",
        "train_validation_merge_1['user_ave_price_day_ratio'] = train_validation_merge_1['user_ave_price_day_ratio'].fillna(train_validation_merge_1['ave_price_day_ratio'])\n",
        "train_validation_merge_2['user_ave_price_day_ratio'] = train_validation_merge_2['user_ave_price_day_ratio'].fillna(train_validation_merge_2['ave_price_day_ratio'])\n",
        "test_validation_merge['user_ave_price_day_ratio'] = test_validation_merge['user_ave_price_day_ratio'].fillna(test_validation_merge['ave_price_day_ratio'])"
      ],
      "metadata": {
        "id": "aHZNl8mK8yMj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0o_trSjQQrl8"
      },
      "outputs": [],
      "source": [
        "train_validation_merge_1['days_between_user_cat_orders'] = train_validation_merge_1['days_between_user_cat_orders'].fillna(train_validation_merge_1['days_between_cat_orders'])\n",
        "train_validation_merge_2['days_between_user_cat_orders'] = train_validation_merge_2['days_between_user_cat_orders'].fillna(train_validation_merge_2['days_between_cat_orders'])\n",
        "test_validation_merge['days_between_user_cat_orders'] = test_validation_merge['days_between_user_cat_orders'].fillna(test_validation_merge['days_between_cat_orders'])\n",
        "train_validation_merge_1.fillna(0, inplace=True)\n",
        "train_validation_merge_2.fillna(0, inplace=True)\n",
        "test_validation_merge.fillna(0, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gPL_SFTDQd-c"
      },
      "outputs": [],
      "source": [
        "#concatenate prediction n-1 and n-2 dateFrames\n",
        "train_validation_merge = pd.concat([train_validation_merge_1, train_validation_merge_2], ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cbmLBkhiuQAt"
      },
      "outputs": [],
      "source": [
        "#new features \n",
        "train_validation_merge['since_prior_days_ratio']=train_validation_merge['days_since_prior_order']/train_validation_merge['days_between_orders']\n",
        "train_validation_merge['since_prior_days_cat_ratio']=train_validation_merge['days_since_prior_order']/train_validation_merge['days_between_cat_orders']\n",
        "train_validation_merge['since_prior_days_user_cat_ratio']=train_validation_merge['days_since_prior_order']/train_validation_merge['days_between_user_cat_orders']\n",
        "train_validation_merge['user_unique_cat_ratio']=train_validation_merge['user_unique_cats']/train_validation_merge['user_total_cats']\n",
        "train_validation_merge['user_DPR_user_ratio']=train_validation_merge['user_days_price_ratio_since_prior']/train_validation_merge['user_ave_price_day_ratio']\n",
        "train_validation_merge['user_DPR_tot_ratio']=train_validation_merge['user_days_price_ratio_since_prior']/train_validation_merge['ave_price_day_ratio']\n",
        "\n",
        "test_validation_merge['since_prior_days_ratio']=test_validation_merge['days_since_prior_order']/test_validation_merge['days_between_orders']\n",
        "test_validation_merge['since_prior_days_cat_ratio']=test_validation_merge['days_since_prior_order']/test_validation_merge['days_between_cat_orders']\n",
        "test_validation_merge['since_prior_days_user_cat_ratio']=test_validation_merge['days_since_prior_order']/test_validation_merge['days_between_user_cat_orders']\n",
        "test_validation_merge['user_unique_cat_ratio']=test_validation_merge['user_unique_cats']/train_validation_merge['user_total_cats']\n",
        "test_validation_merge['user_DPR_user_ratio']=test_validation_merge['user_days_price_ratio_since_prior']/train_validation_merge['user_ave_price_day_ratio']\n",
        "test_validation_merge['user_DPR_tot_ratio']=test_validation_merge['user_days_price_ratio_since_prior']/train_validation_merge['ave_price_day_ratio']\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test_validation_merge.isin([np.inf, -np.inf]).sum()"
      ],
      "metadata": {
        "id": "epn44nkn59zC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dj0OLU1ZTS_g"
      },
      "outputs": [],
      "source": [
        "# print(train_validation_merge_1.shape)\n",
        "# print(train_validation_merge_2.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%html\n",
        "<!DOCTYPE html><html><body align=\"right\"><br><div style=\"direction:;ltr\"><p style=\"background-color: #F7FFCA; color:black; border:1px solid black; border-radius: 10px; font-size:32px; line-height:1.8; font-family: byekan; text-align:justify; padding-left: 50px; padding-right: 50px; padding: 15px;\" >\n",
        "Save Prepared Data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "id": "_QHdRsUrAknN",
        "outputId": "25ef43d9-90b2-492b-caf8-c81e2f298250"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<!DOCTYPE html><html><body align=\"right\"><br><div style=\"direction:;ltr\"><p style=\"background-color: #F7FFCA; color:black; border:1px solid black; border-radius: 10px; font-size:32px; line-height:1.8; font-family: byekan; text-align:justify; padding-left: 50px; padding-right: 50px; padding: 15px;\" >\n",
              "Save Prepared Data\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N8VY0DBu8LOJ"
      },
      "outputs": [],
      "source": [
        "train_validation_merge.to_csv('train_validation_merge_v2.2.csv')\n",
        "test_validation_merge.to_csv('test_validation_merge_v2.2.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dwNNmTWcNiTu"
      },
      "outputs": [],
      "source": [
        "# train_validation_merge = pd.read_csv('train_validation_merge_v2.csv',index_col=0)\n",
        "# test_validation_merge = pd.read_csv('test_validation_merge_v2.csv',index_col=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nwThquHGXdMm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64def1a3-b8fe-4040-f8cc-9ab8f14e161c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['cid', 'bid', 'catid', 'classid', 'reorder_label',\n",
              "       'days_since_prior_order', 'day_of_week', 'checkoutdate', 'user_id',\n",
              "       'user_cat_reorder_rate', 'user_total_cats', 'user_avg_cart_size',\n",
              "       'days_between_orders', 'user_unique_cats', 'user_reordered_cats',\n",
              "       'user_reordered_cats_ratio', 'user_unique_classes',\n",
              "       'user_reordered_classes', 'user_reordered_classes_ratio',\n",
              "       'cat_week_reorder_rate', 'class_week_reorder_rate',\n",
              "       't_days_since_prior_order_reorder_rate',\n",
              "       'c_days_since_prior_order_reorder_rate',\n",
              "       'u_days_since_prior_order_reorder_rate',\n",
              "       'u_t_days_since_prior_reorder_rate',\n",
              "       'u_c_days_since_prior_reorder_rate', 'ave_price_day_ratio',\n",
              "       'days_between_cat_orders', 'cat_reorder_rate', 'p_reduced_feat_1',\n",
              "       'p_reduced_feat_2', 'p_reduced_feat_3', 'u_t_order_rate',\n",
              "       'u_t_reorder_rate', 'user_ave_price_day_ratio',\n",
              "       'days_between_user_cat_orders', 'user_days_price_ratio_since_prior',\n",
              "       'u_t_orders_since_last', 'u_c_orders_since_last', 'max_streak_cat',\n",
              "       'since_prior_days_ratio', 'since_prior_days_cat_ratio',\n",
              "       'since_prior_days_user_cat_ratio', 'user_unique_cat_ratio',\n",
              "       'user_DPR_user_ratio', 'user_DPR_tot_ratio'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ],
      "source": [
        "train_validation_merge.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FGeeETRDXeBG"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XJTu12klhX6Y"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ASnnbBffhbJ-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T7Cr3dKXhkep"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}